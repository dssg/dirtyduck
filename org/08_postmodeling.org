#+STARTUP: showeverything
#+STARTUP: nohideblocks
#+STARTUP: indent
#+STARTUP: align
#+STARTUP: inlineimages
#+STARTUP: latexpreview
#+PROPERTY: header-args:sql :engine postgresql
#+PROPERTY: header-args:sql+ :dbhost 0.0.0.0
#+PROPERTY: header-args:sql+ :dbport 5434
#+PROPERTY: header-args:sql+ :dbuser food_user
#+PROPERTY: header-args:sql+ :dbpassword some_password
#+PROPERTY: header-args:sql+ :database food
#+PROPERTY: header-args:sql+ :results table drawer
#+PROPERTY: header-args:sql+ :exports both
#+PROPERTY: header-args:sql+ :eval no-export
#+PROPERTY: header-args:sql+ :cmdline -q
#+PROPERTY: header-args:sh  :results verbatim org
#+PROPERTY: header-args:sh+ :prologue exec 2>&1 :epilogue :
#+PROPERTY: header-args:ipython   :session food_inspections
#+PROPERTY: header-args:ipython+ :results raw drawer
#+OPTIONS: broken-links:mark
#+OPTIONS: tasks:todo
#+OPTIONS: LaTeX:t

* WORKING Audition: How can I pick the best one?

Now you have *42* /model groups/. Which is best? Which should you choose to
use? This is not as easy as it sounds, due to several factors:

- You can try to pick the best using a metric
  specified in the config file (=precision@= and =recall@=),
  but at what point of time? Maybe different model groups are best
  at different prediction times.
- You can just use the one that performs best on the last test set.
- You can value a model group that provides consistent results over time.
  It might not be the best on any test set, but you can feel more
  confident that it will continue to perform similarly.
- If there are several model groups that perform similarly and
  their lists are more or less similar, maybe it doesn't really
  matter which you pick.

The answers to questions like these may not be obvious up front.

Triage provides this functionality in =audition= and in
=postmodel=. At the moment of this writing, these two modules require
more interaction (i.e. they aren't integrated with the /configuration
file/).

Audition is a tool for picking the best trained classifiers from a
predictive analytics experiment.  Audition introduces
a structured, semi-automated way of filtering models based on what you
consider important.

=Audition= formalizes this idea through /selection rules/ that take in
the data up to a given point in time, apply some rule to choose a
model group, and then evaluate the performance (*regret*) of the chosen
model group in the subsequent time window.

=Audition= predefines 7 rules:

1. =best_current_value= :: Pick the model group with the best current metric Value.
2. =best_average_value= :: Pick the model with the highest average metric value so far.
3. =lowest_metric_variance= :: Pick the model with the lowest metric variance so far.
4. =most_frequent_best_dist= :: Pick the model that is most frequently
     within =dist_from_best_case= from the best-performing model group
     across test sets so far.
5. =best_average_two_metrics= :: Pick the model with the highest
     average combined value to date of two metrics weighted together
     using =metric1_weight=.
6. =best_avg_var_penalized= :: Pick the model with the highest average
     metric value so far, penalized for relative variance ss:
     =avg_value - (stdev_penalty) * (stdev - min_stdev)= where
     =min_stdev= is the minimum standard deviation of the metric
     across all model groups
7.  =best_avg_recency_weight= :: Pick the model with the highest
     average metric value so far, penalized for relative variance as:
     =avg_value - (stdev_penalty) * (stdev - min_stdev)= where
     =min_stdev= is the minimum standard deviation of the metric
     across all  model groups

We included a simple configuration file with some rules:

#+BEGIN_SRC yaml :tangle ../triage/audition_config.yaml
# CHOOSE MODEL GROUPS
model_groups:
    query: |
        SELECT DISTINCT(model_group_id)
        FROM model_metadata.model_groups
# CHOOSE TIMESTAMPS/TRAIN END TIMES
time_stamps:
    query: |
        SELECT DISTINCT train_end_time
        FROM model_metadata.models
        WHERE model_group_id IN ({})
        AND EXTRACT(DAY FROM train_end_time) IN (1)
        AND train_end_time >= '2012-01-01'
# FILTER
filter:
    metric: 'precision@' # metric of interest
    parameter: '10_pct' # parameter of interest
    max_from_best: 1.0 # The maximum value that the given metric can be worse than the best model for a given train end time.
    threshold_value: 0.0 # The worst absolute value that the given metric should be.
    distance_table: 'distance_table' # name of the distance table
    models_table: 'models' # name of the models table

# RULES
rules:
    -
        shared_parameters:
            -
                metric: 'precision@'
                parameter: '10_pct'

        selection_rules:
            -
                name: 'best_current_value' # Pick the model group with the best current metric value
                n: 3
            -
                name: 'best_average_value' # Pick the model with the highest average metric value
                n: 3
            -
                name: 'lowest_metric_variance' # Pick the model with the lowest metric variance
                n: 3
            -
                name: 'most_frequent_best_dist' # Pick the model that is most frequently within `dist_from_best_case`
                dist_from_best_case: [0.05]
                n: 3

#+END_SRC

=Audition= will have each rule give you the best $n$ model-group IDs
based on the metric and parameter following that rule for the most
recent time period (in all the rules shown $n$ = 1).

We can run the simulation of the rules againts the experiment as:

#+BEGIN_SRC sh :dir /docker:root@tutorial_bastion:/triage :exports both :results output
triage --tb audition --directory images
:
#+END_SRC

#+RESULTS:
#+BEGIN_SRC org
/usr/local/lib/python3.6/site-packages/psycopg2/__init__.py:144: UserWarning: The psycopg2 wheel package will be renamed from release 2.8; in order to keep installing from binary please use "pip install psycopg2-binary" instead. For details see: <http://initd.org/psycopg/docs/install.html#binary-install-from-pypi>.
  """)
INFO:root:Validate!
INFO:root:Checking if all model groups have the same train end times
INFO:root:Found 45 total model groups
INFO:root:Dropped 36 model groups which don't match the train end times
INFO:root:Found 9 total model groups past the checker
INFO:root:Polulating data to distance table
INFO:root:Showing best distance plots for all metrics
INFO:root:Found 9 model groups close to best for 2015-12-01 00:00:00
INFO:root:Found 9 model groups above min for 2015-12-01 00:00:00
INFO:root:Found 9 model groups close to best for 2016-12-01 00:00:00
INFO:root:Found 9 model groups above min for 2016-12-01 00:00:00
INFO:root:Found 9 model groups close to best for 2017-12-01 00:00:00
INFO:root:Found 9 model groups above min for 2017-12-01 00:00:00
INFO:root:Found 9 total model groups past threshold
INFO:root:Building best distance plot for {'metric': 'precision@', 'parameter': '10_pct'} and [Timestamp('2015-12-01 00:00:00'), Timestamp('2016-12-01 00:00:00'), Timestamp('2017-12-01 00:00:00')]
INFO:root:Showing model group performance plots for all metrics
INFO:root:Plotting model group performance for {'metric': 'precision@', 'parameter': '10_pct', 'max_from_best': 1.0, 'threshold_value': 0.0}, [Timestamp('2015-12-01 00:00:00'), Timestamp('2016-12-01 00:00:00'), Timestamp('2017-12-01 00:00:00')]
INFO:root:Expanding selection rule groups into full grid
INFO:root:Expanding rule group {'shared_parameters': [{'metric': 'precision@', 'parameter': '10_pct'}], 'selection_rules': [{'name': 'best_current_value', 'n': 3}, {'name': 'best_average_value', 'n': 3}, {'name': 'lowest_metric_variance', 'n': 3}, {'name': 'most_frequent_best_dist', 'dist_from_best_case': [0.05], 'n': 3}]}
INFO:root:Expanding shared param set {'metric': 'precision@', 'parameter': '10_pct'} and selection rules {'name': 'best_current_value', 'n': 3}
INFO:root:Found 1 new rules
INFO:root:Expanding shared param set {'metric': 'precision@', 'parameter': '10_pct'} and selection rules {'name': 'best_average_value', 'n': 3}
INFO:root:Found 1 new rules
INFO:root:Expanding shared param set {'metric': 'precision@', 'parameter': '10_pct'} and selection rules {'name': 'lowest_metric_variance', 'n': 3}
INFO:root:Found 1 new rules
INFO:root:Expanding shared param set {'metric': 'precision@', 'parameter': '10_pct'} and selection rules {'name': 'most_frequent_best_dist', 'dist_from_best_case': [0.05], 'n': 3}
INFO:root:Found 1 new rules
INFO:root:Found 4 total selection rules. Full list: ['best_current_value_precision@_10_pct', 'best_average_value_precision@_10_pct', 'lowest_metric_variance_precision@_10_pct', 'most_frequent_best_dist_precision@_10_pct_0.05']
INFO:root:Found 9 model groups close to best for 2015-12-01 00:00:00
INFO:root:Found 9 model groups above min for 2015-12-01 00:00:00
INFO:root:Found 9 model groups close to best for 2016-12-01 00:00:00
INFO:root:Found 9 model groups above min for 2016-12-01 00:00:00
INFO:root:Found 9 model groups close to best for 2017-12-01 00:00:00
INFO:root:Found 9 model groups above min for 2017-12-01 00:00:00
INFO:root:Found 9 total model groups past threshold
INFO:root:Null metric variances for precision@ 10_pct at 2015-12-01 00:00:00; picking at random
INFO:root:Null metric variances for precision@ 10_pct at 2015-12-01 00:00:00; picking at random
INFO:root:Calculating selection rule picks for all rules
INFO:root:Found 9 model groups close to best for 2015-12-01 00:00:00
INFO:root:Found 9 model groups above min for 2015-12-01 00:00:00
INFO:root:Found 9 model groups close to best for 2016-12-01 00:00:00
INFO:root:Found 9 model groups above min for 2016-12-01 00:00:00
INFO:root:Found 9 model groups close to best for 2017-12-01 00:00:00
INFO:root:Found 9 model groups above min for 2017-12-01 00:00:00
INFO:root:Found 9 total model groups past threshold
INFO:root:Calculating selection rule picks for best_current_value_precision@_10_pct
INFO:root:For rule best_current_value_precision@_10_pct, model group [7, 6, 5] was picked
INFO:root:Calculating selection rule picks for best_average_value_precision@_10_pct
INFO:root:For rule best_average_value_precision@_10_pct, model group [6, 7, 4] was picked
INFO:root:Calculating selection rule picks for lowest_metric_variance_precision@_10_pct
INFO:root:For rule lowest_metric_variance_precision@_10_pct, model group [1, 2, 3] was picked
INFO:root:Calculating selection rule picks for most_frequent_best_dist_precision@_10_pct_0.05
INFO:root:For rule most_frequent_best_dist_precision@_10_pct_0.05, model group [6, 4, 5] was picked
INFO:root:Audition ran! Results are stored in images.
[0m
#+END_SRC

* TODO Postmodeling


* TODO Crossvalidation
