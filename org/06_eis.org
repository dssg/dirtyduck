#+STARTUP: showeverything
#+STARTUP: nohideblocks
#+STARTUP: indent
#+STARTUP: align
#+STARTUP: inlineimages
#+STARTUP: latexpreview
#+PROPERTY: header-args:sql :engine postgresql
#+PROPERTY: header-args:sql+ :dbhost 0.0.0.0
#+PROPERTY: header-args:sql+ :dbport 5434
#+PROPERTY: header-args:sql+ :dbuser food_user
#+PROPERTY: header-args:sql+ :dbpassword some_password
#+PROPERTY: header-args:sql+ :database food
#+PROPERTY: header-args:sql+ :results table drawer
#+PROPERTY: header-args:sql+ :exports both
#+PROPERTY: header-args:sql+ :eval no-export
#+PROPERTY: header-args:sql+ :cmdline -q
#+PROPERTY: header-args:sh  :results verbatim org
#+PROPERTY: header-args:sh+ :prologue exec 2>&1 :epilogue :
#+PROPERTY: header-args:ipython   :session food_inspections
#+PROPERTY: header-args:ipython+ :results raw drawer
#+PROPERTY: header-args:yaml :eval no-export
#+OPTIONS: broken-links:mark
#+OPTIONS: tasks:todo
#+OPTIONS: LaTeX:t

* An Early Intervention System

** Problem description

=triage= is designed to also build early warning systems (also called early intervention, EIS).
While there are  several differences between modeling early warnings and inspection
 prioritization, perhaps the biggest is that  the /entity/ is active
(i.e. it is doing stuff for which
 an outcome will happen) in EIS but passive (i.e. inspected)
 in *inspection prioritization*. Among other things, this difference
affects the way the /outcome/ is built.

Here's the question we want to answer:

#+begin_quote
Will my restaurant be inspected in the
/next X period of time?/
#+end_quote

Where $X$ could be 3 days, 2 months, 1 year,
etc.

  Knowing the answer to this question enables you (as the restaurant
  owner or manager) to prepare for the inspection.


** What are the labels? What are the outcomes?

The trick to note is that on any given day there are two possible outcomes:
/the facility was inspected/ and /the facility wasn't inspected/.
Our /outcomes/ table will be larger than in the inspection prioritization example
because we need an /outcome/ for every /active/ facility on every date.
The following image tries to exemplify this reasoning:


#+NAME: fig:outcomes-inspections
#+CAPTION: The image shows three facilities, and next to each, a temporal line with 6 days (0-5). Each dot represents the event (whether an inspection happened). Yellow means the inspection happened (=TRUE= outcome) and blue means it didn't (=FALSE= outcome). Each facility in the image had two inspections, six in total.
#+ATTR_ORG: :width 600 :height 400
#+ATTR_HTML: :width 600 :height 400
#+ATTR_LATEX: :width 400 :height 300
[[./images/outcomes-eis.png]]

Fortunately, =triage= will help us to create this table. The /cohort/
table is the same as the /cohort/ table in the inspection case.


First the usual stuff. Note that we are changing =model_comment= and
=label_definition= (remember that this is used for generating the
/hash/ that differentiates models and model groups).

#+BEGIN_SRC yaml :tangle ../triage/experiments/eis_01.yaml
config_version: 'v6'

model_comment: 'eis: 01'

user_metadata:
  label_definition: 'inspected'
  experiment_type: 'eis'
  description: |
    EIS 01
  purpose: 'model creation'
  org: 'DSaPP'
  team: 'Tutorial'
  author: 'Your name here'
  etl_date: '2019-02-21'

model_group_keys:
  - 'class_path'
  - 'parameters'
  - 'feature_names'
  - 'feature_groups'
  - 'cohort_name'
  - 'state'
  - 'label_name'
  - 'label_timespan'
  - 'training_as_of_date_frequency'
  - 'max_training_history'
  - 'label_definition'
  - 'experiment_type'
  - 'org'
  - 'team'
  - 'author'
  - 'purpose'
  - 'etl_date'

#+END_SRC

For the labels the query is pretty simple, if the facility showed in
the data, it will get a /positive/ outcome, if not they will get a /negative/ outcome

#+BEGIN_SRC yaml :tangle ../triage/experiments/eis_01.yaml
label_config:
  query: |
    select
    entity_id,
    True::integer as outcome
    from semantic.events
    where '{as_of_date}'::timestamp <= date
    and date < '{as_of_date}'::timestamp + interval '{label_timespan}'
    group by entity_id
  include_missing_labels_in_train_as: False
  name: 'inspected'
#+END_SRC

Note the two introduced changes in this block, first, the /outcome/ is
=True= , because all our observations represent /inspected/ facilities
(see discussion above and in particular previous image), second, we
added the line =include_missing_labels_in_train_as: False=. This line
tells =triage= to incorporate all the missing facilities in the
/training/ matrices with =False= as the /label/.

As stated we will use the same configuration block for /cohorts/ that we
used in inspections:

#+BEGIN_SRC yaml :tangle ../triage/experiments/eis_01.yaml
cohort_config:
  query: |
    with buckets as (
    select *, ntile(5) over (order by number_of_inspections asc) as bucket
    from (
    select entity_id, count(*) as number_of_inspections
    from semantic.events
    group by entity_id
    ) as t
    )
    select e.entity_id
    from semantic.entities as e
    inner join
    buckets as b
    using (entity_id)
    where
    daterange(start_time, end_time, '[]') @> '{as_of_date}'::date
    and bucket in (5)
  name: 'active_facilities'
#+END_SRC


** Modeling Using Machine Learning

We need to specify the temporal configuration too

**** Temporal configuration
#+BEGIN_SRC yaml :tangle ../triage/experiments/eis_01.yaml
temporal_config:
    feature_start_time: '2010-01-04'
    feature_end_time: '2019-01-01'
    label_start_time: '2015-02-01'
    label_end_time: '2019-01-01'

    model_update_frequency: '1y'
    training_label_timespans: ['1month']
    training_as_of_date_frequencies: '1month'

    test_durations: '1y'
    test_label_timespans: ['1month']
    test_as_of_date_frequencies: '1month'

    max_training_histories: '5y'
#+END_SRC


As before, you can generate the image of the temporal blocks:


#+BEGIN_SRC sh :dir /docker:root@tutorial_bastion:/triage :results silent
# Remember to run this in bastion  NOT in your laptop shell!
triage experiment experiments/eis_01.yaml --show-timechop
#+END_SRC


#+CAPTION: Temporal blocks for the Early Warning System. We want to predict the most likely facilities to be inspected in the following month.
#+ATTR_ORG: :width 600 :height 400
#+ATTR_HTML: :width 600 :height 600
#+ATTR_LATEX: :width 400 :height 300
[[file:triage/images/eis_01.png]]

**** Features

Regarding the features, we will use the same ones that were used in [[file:inspections.org][inspections prioritization]]:

#+BEGIN_SRC yaml :tangle ../triage/experiments/eis_01.yaml
feature_aggregations:
  -
    prefix: 'inspections'
    from_obj: 'semantic.events'
    knowledge_date_column: 'date'

    aggregates_imputation:
      count:
        type: 'zero_noflag'

    aggregates:
      -
        quantity:
          total: "*"
        metrics:
          - 'count'

    intervals: ['1month', '3month', '6month', '1y', 'all']

    groups:
      - 'entity_id'

  -
    prefix: 'risks'
    from_obj: 'semantic.events'
    knowledge_date_column: 'date'

    categoricals_imputation:
      sum:
        type: 'zero'
      avg:
        type: 'zero'

    categoricals:
      -
        column: 'risk'
        choices: ['low', 'medium', 'high']
        metrics:
          - 'sum'
          - 'avg'

    intervals: ['1month', '3month', '6month', '1y', 'all']

    groups:
      - 'entity_id'
      - 'zip_code'

  -
    prefix: 'results'
    from_obj: 'semantic.events'
    knowledge_date_column: 'date'

    categoricals_imputation:
      all:
        type: 'zero'

    categoricals:
      -
        column: 'result'
        choice_query: 'select distinct result from semantic.events'
        metrics:
          - 'sum'
          - 'avg'

    intervals: ['1month', '3month', '6month', '1y', 'all']

    groups:
      - 'entity_id'

  -
    prefix: 'inspection_types'
    from_obj: 'semantic.events'
    knowledge_date_column: 'date'

    categoricals_imputation:
      sum:
        type: 'zero_noflag'

    categoricals:
      -
        column: 'type'
        choice_query: 'select distinct type from semantic.events where type is not null'
        metrics:
          - 'sum'

    intervals: ['1month', '3month', '6month', '1y', 'all']

    groups:
      - 'entity_id'
      - 'zip_code'


#+END_SRC

We declare that we want to use all possible feature-group combinations for training:

#+BEGIN_SRC yaml :tangle ../triage/experiments/eis_01.yaml
feature_group_definition:
   prefix:
     - 'inspections'
     - 'results'
     - 'risks'
     - 'inspection_types'

feature_group_strategies: ['all', 'leave-one-out', 'leave-one-in']
#+END_SRC

i.e. =all= will train models with all the features groups,
=leave-one-in= will use only one of the feature groups for traning, and
lastly, =leave-one-out= will train the model with all the features
except one.

**** Algorithm and hyperparameters

We will collapse the baseline (=DummyClassifier=) and the exploratory configuration together:

#+BEGIN_SRC yaml :tangle ../triage/experiments/eis_01.yaml
grid_config:
    'sklearn.tree.DecisionTreeClassifier':
        max_depth: [2,null]
    'sklearn.ensemble.RandomForestClassifier':
        max_features: ['sqrt']
        criterion: ['gini']
        n_estimators: [500]
        min_samples_leaf: [1]
        min_samples_split: [50]
    'sklearn.dummy.DummyClassifier':
        strategy: [most_frequent]
#+END_SRC

=triage= will create *36* /model groups/: *4* algorithms and
hyperparameters (2 =DecisionTreeClassifier=, 1
=RandomForestClassifier=, 1 =DummyClassifier=) \times *9* features sets (1
=all=, 4 =leave-one-out=, =4 leave-one-in=). The total number of /models/
is three times that (we have 3 time blocks, so *108* models).

#+BEGIN_SRC yaml :tangle ../triage/experiments/eis_01.yaml
scoring:
    testing_metric_groups:
        -
          metrics: [precision@, recall@]
          thresholds:
            percentiles: [1.0, 2.0, 3.0, 4.0, 5.0, 10, 15, 20, 25, 30, 35, 40, 45, 50, 55, 60, 65, 70, 75, 80, 85, 90, 95, 100]
            top_n: [1, 5, 10, 25, 50, 100, 250, 500, 1000]


    training_metric_groups:
      -
        metrics: [accuracy]
      -
        metrics: [precision@, recall@]
        thresholds:
          percentiles: [1.0, 2.0, 3.0, 4.0, 5.0, 10, 15, 20, 25, 30, 35, 40, 45, 50, 55, 60, 65, 70, 75, 80, 85, 90, 95, 100]
          top_n: [1, 5, 10, 25, 50, 100, 250, 500, 1000]

#+END_SRC

As a last step, we validate that the configuration file is correct:


#+BEGIN_SRC sh :dir /docker:root@tutorial_bastion:/ :results silent

# Remember to run this in bastion  NOT in your laptop shell!
triage experiment experiments/eis_01.yaml  --validate-only
#+END_SRC


And then just run it:

#+BEGIN_SRC sh :dir /docker:root@tutorial_bastion:/ :results silent
# Remember to run this in bastion  NOT in your laptop shell!
triage experiment --matrix-format hdf experiments/eis_01.yaml --profile
#+END_SRC

This will take a *lot* amount of time (on my computer took 3h 42m),
so, grab your coffee, chat with
your coworkers, check your email, or read the [[https://dssg.uchicago.edu/blog][DSSG blog]].
It's taking that long for several reasons:

1. There are a lot of models, parameters, etc.
2. We are running in serial mode (i.e. not in parallel).
3. The database is running on your laptop.

You can solve 2 and 3. For the second point you could use the =docker=
container that has the multicore option enabled. For 3, I recommed you
to use a PostgreSQL database in the cloud, such as Amazon's
*PostgreSQL RDS* (we will explore this later in running triage in AWS Batch).

After the experiment finishes, we can create the following table:

#+BEGIN_SRC sql
with features_groups as (
select
    model_group_id,
    split_part(unnest(feature_list), '_', 1) as feature_groups
from
    model_metadata.model_groups
),

features_arrays as (
select
    model_group_id,
    array_agg(distinct feature_groups) as feature_groups
from
    features_groups
group by
    model_group_id
)

select
    model_group_id,
    model_type,
    hyperparameters,
    feature_groups,
    array_agg(model_id) as models,
    array_agg(train_end_time::date order by train_end_time asc) as times,
    array_agg(to_char(value, '0.999') order by train_end_time asc) as "precision@10%"
from
    model_metadata.models
    join
    features_arrays using(model_group_id)
    join
    test_results.evaluations using(model_id)
where
    model_comment ~ 'eis'
    and
    metric || parameter = 'precision@10_pct'
group by
    model_group_id,
    model_type,
    hyperparameters,
    feature_groups
order by
    model_group_id;
#+END_SRC

#+RESULTS:
:RESULTS:
| model_group_id | model_type                               | hyperparameters                                                                                              | feature_groups                          | models        | times                              | precision@10%                |
|--------------+-----------------------------------------+--------------------------------------------------------------------------------------------------------------+----------------------------------------+---------------+------------------------------------+------------------------------|
|           46 | sklearn.tree.DecisionTreeClassifier     | {"max_depth": 2}                                                                                              | {inspection,inspections,results,risks} | {172,136,154} | {2015-12-01,2016-12-01,2017-12-01} | {" 0.271"," 0.265"," 0.181"} |
|           47 | sklearn.tree.DecisionTreeClassifier     | {"max_depth": null}                                                                                           | {inspection,inspections,results,risks} | {137,155,173} | {2015-12-01,2016-12-01,2017-12-01} | {" 0.200"," 0.211"," 0.138"} |
|           48 | sklearn.tree.DecisionTreeClassifier     | {"max_depth": 2}                                                                                              | {inspection,results,risks}             | {156,138,174} | {2015-12-01,2016-12-01,2017-12-01} | {" 0.271"," 0.265"," 0.181"} |
|           49 | sklearn.tree.DecisionTreeClassifier     | {"max_depth": null}                                                                                           | {inspection,results,risks}             | {175,139,157} | {2015-12-01,2016-12-01,2017-12-01} | {" 0.197"," 0.213"," 0.138"} |
|           50 | sklearn.tree.DecisionTreeClassifier     | {"max_depth": 2}                                                                                              | {inspection,inspections,risks}         | {158,140,176} | {2015-12-01,2016-12-01,2017-12-01} | {" 0.253"," 0.224"," 0.142"} |
|           51 | sklearn.tree.DecisionTreeClassifier     | {"max_depth": null}                                                                                           | {inspection,inspections,risks}         | {177,141,159} | {2015-12-01,2016-12-01,2017-12-01} | {" 0.175"," 0.171"," 0.129"} |
|           52 | sklearn.tree.DecisionTreeClassifier     | {"max_depth": 2}                                                                                              | {inspection,inspections,results}       | {178,142,160} | {2015-12-01,2016-12-01,2017-12-01} | {" 0.271"," 0.265"," 0.181"} |
|           53 | sklearn.tree.DecisionTreeClassifier     | {"max_depth": null}                                                                                           | {inspection,inspections,results}       | {143,161,179} | {2015-12-01,2016-12-01,2017-12-01} | {" 0.213"," 0.201"," 0.133"} |
|           54 | sklearn.tree.DecisionTreeClassifier     | {"max_depth": 2}                                                                                              | {inspections,results,risks}            | {162,180,144} | {2015-12-01,2016-12-01,2017-12-01} | {" 0.271"," 0.265"," 0.181"} |
|           55 | sklearn.tree.DecisionTreeClassifier     | {"max_depth": null}                                                                                           | {inspections,results,risks}            | {163,145,181} | {2015-12-01,2016-12-01,2017-12-01} | {" 0.204"," 0.205"," 0.146"} |
|           56 | sklearn.tree.DecisionTreeClassifier     | {"max_depth": 2}                                                                                              | {inspections}                          | {164,182,146} | {2015-12-01,2016-12-01,2017-12-01} | {" 0.171"," 0.145"," 0.113"} |
|           57 | sklearn.tree.DecisionTreeClassifier     | {"max_depth": null}                                                                                           | {inspections}                          | {165,183,147} | {2015-12-01,2016-12-01,2017-12-01} | {" 0.168"," 0.168"," 0.131"} |
|           58 | sklearn.tree.DecisionTreeClassifier     | {"max_depth": 2}                                                                                              | {results}                              | {148,166,184} | {2015-12-01,2016-12-01,2017-12-01} | {" 0.271"," 0.265"," 0.181"} |
|           59 | sklearn.tree.DecisionTreeClassifier     | {"max_depth": null}                                                                                           | {results}                              | {149,185,167} | {2015-12-01,2016-12-01,2017-12-01} | {" 0.243"," 0.232"," 0.180"} |
|           60 | sklearn.tree.DecisionTreeClassifier     | {"max_depth": 2}                                                                                              | {risks}                                | {168,150,186} | {2015-12-01,2016-12-01,2017-12-01} | {" 0.253"," 0.224"," 0.142"} |
|           61 | sklearn.tree.DecisionTreeClassifier     | {"max_depth": null}                                                                                           | {risks}                                | {151,169,187} | {2015-12-01,2016-12-01,2017-12-01} | {" 0.174"," 0.158"," 0.122"} |
|           62 | sklearn.tree.DecisionTreeClassifier     | {"max_depth": 2}                                                                                              | {inspection}                           | {170,188,152} | {2015-12-01,2016-12-01,2017-12-01} | {" 0.201"," 0.191"," 0.124"} |
|           63 | sklearn.tree.DecisionTreeClassifier     | {"max_depth": null}                                                                                           | {inspection}                           | {171,153,189} | {2015-12-01,2016-12-01,2017-12-01} | {" 0.166"," 0.165"," 0.124"} |
|           64 | sklearn.ensemble.RandomForestClassifier | {"criterion": "gini", "max_features": "sqrt", "n_estimators": 500, "min_samples_leaf": 1, "min_samples_split": 50} | {inspection,inspections,results,risks} | {190,208,226} | {2015-12-01,2016-12-01,2017-12-01} | {" 0.348"," 0.346"," 0.239"} |
|           65 | sklearn.dummy.DummyClassifier           | {"strategy": "most_frequent"}                                                                                 | {inspection,inspections,results,risks} | {227,191,209} | {2015-12-01,2016-12-01,2017-12-01} | {" 0.121"," 0.119"," 0.088"} |
|           66 | sklearn.ensemble.RandomForestClassifier | {"criterion": "gini", "max_features": "sqrt", "n_estimators": 500, "min_samples_leaf": 1, "min_samples_split": 50} | {inspection,results,risks}             | {192,228,210} | {2015-12-01,2016-12-01,2017-12-01} | {" 0.350"," 0.348"," 0.244"} |
|           67 | sklearn.dummy.DummyClassifier           | {"strategy": "most_frequent"}                                                                                 | {inspection,results,risks}             | {229,211,193} | {2015-12-01,2016-12-01,2017-12-01} | {" 0.121"," 0.119"," 0.088"} |
|           68 | sklearn.ensemble.RandomForestClassifier | {"criterion": "gini", "max_features": "sqrt", "n_estimators": 500, "min_samples_leaf": 1, "min_samples_split": 50} | {inspection,inspections,risks}         | {212,230,194} | {2015-12-01,2016-12-01,2017-12-01} | {" 0.283"," 0.271"," 0.186"} |
|           69 | sklearn.dummy.DummyClassifier           | {"strategy": "most_frequent"}                                                                                 | {inspection,inspections,risks}         | {231,195,213} | {2015-12-01,2016-12-01,2017-12-01} | {" 0.121"," 0.119"," 0.088"} |
|           70 | sklearn.ensemble.RandomForestClassifier | {"criterion": "gini", "max_features": "sqrt", "n_estimators": 500, "min_samples_leaf": 1, "min_samples_split": 50} | {inspection,inspections,results}       | {232,196,214} | {2015-12-01,2016-12-01,2017-12-01} | {" 0.339"," 0.335"," 0.245"} |
|           71 | sklearn.dummy.DummyClassifier           | {"strategy": "most_frequent"}                                                                                 | {inspection,inspections,results}       | {197,215,233} | {2015-12-01,2016-12-01,2017-12-01} | {" 0.121"," 0.119"," 0.088"} |
|           72 | sklearn.ensemble.RandomForestClassifier | {"criterion": "gini", "max_features": "sqrt", "n_estimators": 500, "min_samples_leaf": 1, "min_samples_split": 50} | {inspections,results,risks}            | {216,234,198} | {2015-12-01,2016-12-01,2017-12-01} | {" 0.344"," 0.342"," 0.239"} |
|           73 | sklearn.dummy.DummyClassifier           | {"strategy": "most_frequent"}                                                                                 | {inspections,results,risks}            | {199,217,235} | {2015-12-01,2016-12-01,2017-12-01} | {" 0.121"," 0.119"," 0.088"} |
|           74 | sklearn.ensemble.RandomForestClassifier | {"criterion": "gini", "max_features": "sqrt", "n_estimators": 500, "min_samples_leaf": 1, "min_samples_split": 50} | {inspections}                          | {218,236,200} | {2015-12-01,2016-12-01,2017-12-01} | {" 0.168"," 0.169"," 0.131"} |
|           75 | sklearn.dummy.DummyClassifier           | {"strategy": "most_frequent"}                                                                                 | {inspections}                          | {219,201,237} | {2015-12-01,2016-12-01,2017-12-01} | {" 0.121"," 0.119"," 0.088"} |
|           76 | sklearn.ensemble.RandomForestClassifier | {"criterion": "gini", "max_features": "sqrt", "n_estimators": 500, "min_samples_leaf": 1, "min_samples_split": 50} | {results}                              | {220,202,238} | {2015-12-01,2016-12-01,2017-12-01} | {" 0.314"," 0.301"," 0.213"} |
|           77 | sklearn.dummy.DummyClassifier           | {"strategy": "most_frequent"}                                                                                 | {results}                              | {221,239,203} | {2015-12-01,2016-12-01,2017-12-01} | {" 0.121"," 0.119"," 0.088"} |
|           78 | sklearn.ensemble.RandomForestClassifier | {"criterion": "gini", "max_features": "sqrt", "n_estimators": 500, "min_samples_leaf": 1, "min_samples_split": 50} | {risks}                                | {204,222,240} | {2015-12-01,2016-12-01,2017-12-01} | {" 0.280"," 0.263"," 0.178"} |
|           79 | sklearn.dummy.DummyClassifier           | {"strategy": "most_frequent"}                                                                                 | {risks}                                | {223,241,205} | {2015-12-01,2016-12-01,2017-12-01} | {" 0.121"," 0.119"," 0.088"} |
|           80 | sklearn.ensemble.RandomForestClassifier | {"criterion": "gini", "max_features": "sqrt", "n_estimators": 500, "min_samples_leaf": 1, "min_samples_split": 50} | {inspection}                           | {242,206,224} | {2015-12-01,2016-12-01,2017-12-01} | {" 0.272"," 0.259"," 0.179"} |
|           81 | sklearn.dummy.DummyClassifier           | {"strategy": "most_frequent"}                                                                                 | {inspection}                           | {225,243,207} | {2015-12-01,2016-12-01,2017-12-01} | {" 0.121"," 0.119"," 0.088"} |
:END:

* WORKING Audition: So many models, how can I choose the best one?

#+BEGIN_SRC yaml :tangle ../triage/eis_audition_config.yaml
# CHOOSE MODEL GROUPS
model_groups:
    query: |
        select distinct(model_group_id)
        from model_metadata.model_groups
        where model_config ->> 'experiment_type' ~ 'eis'
# CHOOSE TIMESTAMPS/TRAIN END TIMES
time_stamps:
    query: |
        select distinct train_end_time
        from model_metadata.models
        where model_group_id in ({})
        and extract(day from train_end_time) in (1)
        and train_end_time >= '2015-01-01'
# FILTER
filter:
    metric: 'precision@' # metric of interest
    parameter: '10_pct' # parameter of interest
    max_from_best: 1.0 # The maximum value that the given metric can be worse than the best model for a given train end time.
    threshold_value: 0.0 # The worst absolute value that the given metric should be.
    distance_table: 'distance_table' # name of the distance table
    models_table: 'models' # name of the models table

# RULES
rules:
    -
        shared_parameters:
            -
                metric: 'precision@'
                parameter: '10_pct'

        selection_rules:
            -
                name: 'best_current_value' # Pick the model group with the best current metric value
                n: 3
            -
                name: 'best_average_value' # Pick the model with the highest average metric value
                n: 3
            -
                name: 'lowest_metric_variance' # Pick the model with the lowest metric variance
                n: 3
            -
                name: 'most_frequent_best_dist' # Pick the model that is most frequently within `dist_from_best_case`
                dist_from_best_case: [0.05]
                n: 3

#+END_SRC

=Audition= will have each rule give you the best $n$ model-group IDs
based on the metric and parameter following that rule for the most
recent time period (in all the rules shown $n$ = 3).

We can run the simulation of the rules againts the experiment as:

#+BEGIN_SRC sh :dir /docker:root@tutorial_bastion:/triage :exports code :results none
triage --tb audition -c eis_audition_config.yaml --directory audition/eis
#+END_SRC

=Audition= will create several plots that will help you to sort out
which is the /best/ model group to use (like in a production setting or
just to generate your list).

** Filtering model groups
:PROPERTIES:
:ORDERED:  t
:END:

=Audition= will generate two plots that are meant to be used together:
/model performance over time/ and /distance from best/.

#+CAPTION: Model group performance over time. In this case the metric show is =precision@10%=. The black dashed line represents the (theoretical) system's performance if we select the best performant model in a every evaluation date. The colored lines represents different model groups. All the model groups that share an algorithm will be colored the same.
#+LABEL: fig:performance-over-time
[[file:audition/eis/metric_over_time_precision@10_pct.png]]


#+CAPTION: Proportion of /models/ in a /model group/ that are separated from the best model in an specific evaluation time. The distance is measured in percentual points, i.e. How much less precision at 10 percent of the population compared to the best model in that date.
#+LABEL: fig:distance-from-best
[[file:audition/eis/distance_from_best_precision@10_pct.png]]

** Selecting the best rule or strategy for choosing model groups

In this phase of the audition, you will see what will happen in the
next time if you choose your model group with an specific strategy or
rule.

You then, can calculate the /regret/. /Regret/ is defined as the
difference between the performance of the best model evaluated on the
"next time" and the performance of the model selected by a particular rule.

#+CAPTION: Given a strategy for selecting model groups (in the plot 4 are shown), What will be the performace of the model group chosen by that strategy in the next evaluation date?
#+LABEL: fig:performance-next-time
[[file:audition/eis/precision@10_pct_next_time.png]]


#+CAPTION: Given a strategy for selecting model groups (in the plot 4 are shown). What will be the distance (/regret/) to the best theoretical model in the following evaluation date? This plot is similar to the [@fig:distance-from-best]
#+LABEL: fig:regret-from-best-given-a-rule
[[file:audition/eis/regret_distance_from_best_rules_precision@10_pct.png]]



#+CAPTION: Expected regret for the strategies. The less the better.
#+LABEL: fig:regret-over-time
[[file:audition/eis/regret_over_time_precision@10_pct.png]]

It seems that the best strategy (the one with the lower “regret”) for selecting
a /model_group/ is =most_frequent_best_dist_precision=



The best *3* /model groups/ per strategy will be stored in the file =[[file:audition/eis/results_model_group_ids.json][results_model_group_ids.json]]=:

#+INCLUDE: ../triage/audition/eis/results_model_group_ids.json src json

In the next two sections, we will investigate further the three model
groups in our best strategy using the /Postmodeling/ tool set, and then
instead of using the feature importance to characterize the
facilities, we will explore how the model is splitting the facilities using
/crosstabs/.


* WORKING Postmodeling: Inspecting the best models closely

/Postmodeling/ will help you to understand the behaviour orf your selected models (from audition)

Compared to the previous sections, /postmodeling/ is not an automated process (yet).

#+BEGIN_SRC yaml :tangle ../triage/eis_postmodeling_config.yaml
# Postmodeling Configuration File

  project_path: '/triage' # Project path defined in triage with matrices and models
  audition_output_path: '/triage/audition/results_model_group_ids.json'



  thresholds: # Thresholds for2 defining positive predictions
        rank_abs: [50, 100, 250]
        rank_pct: [5, 10, 25]

  baseline_query: | # SQL query for defining a baseline for comparison in plots. It needs a metric and parameter
      select g.model_group_id,
             m.model_id,
             extract('year' from m.evaluation_end_time) as as_of_date_year,
             m.metric,
             m.parameter,
             m.value,
             m.num_labeled_examples,
             m.num_labeled_above_threshold,
             m.num_positive_labels
       from test_results.evaluations m
       left join model_metadata.models g
       using(model_id)
       where g.model_group_id = 65
             and metric = 'precision@'
             and parameter = '10_pct'

  max_depth_error_tree: 5 # For error trees, how depth the decision trees should go?
  n_features_plots: 10 # Number of features for importances
  figsize: [12, 12] # Default size for plots
  fontsize: 20 # Default fontsize for plots
#+END_SRC

** Setup

#+BEGIN_SRC sh :dir /docker:root@tutorial_bastion:/root/.local/share/jupyter/runtime/
ls
#+END_SRC

#+RESULTS:
#+BEGIN_SRC org
kernel-8d1fa610-fc02-4273-92ec-094f458667b7.json
#+END_SRC


#+BEGIN_SRC jupyter-python :session /docker:root@tutorial_bastion:/root/.local/share/jupyter/runtime/kernel-f3c540d4-0f52-4d51-a01e-fb6e4ff3ea09.json
import pandas as pd
import numpy as np
from collections import OrderedDict
from utils.aux_funcs import create_pgconn, get_models_ids
from triage.component.catwalk.storage import ProjectStorage, ModelStorageEngine, MatrixStorageEngine
from parameters import PostmodelParameters
from model_evaluator import ModelEvaluator
from model_group_evaluator import ModelGroupEvaluator

params = PostmodelParameters('../triage/eis_postmodeling_config.yaml')
#+END_SRC


** Over time

#+BEGIN_SRC jupyter-python :session /docker:root@a2eb002339bd:/root/.local/share/jupyter/runtime/kernel-8d1fa610-fc02-4273-92ec-094f458667b7.json
print("Hola")
#+END_SRC


** Feature group importance

** Higher ratio across labels from =crosstabs=

** Overlap

* WORKING Crossvalidation: How are the entities classified?

Model interpretation is a huge topic nowadays, the most obvious path
is using the /features importance/ from the model. This could be useful,
but we could do a lot better.

=Triage= uses =crosstabs= as a different approach that complements the list of
/features importance/. =crosstabs= will run statistical tests to compare
the predicted positive and the predicted false facilities in /each/
feature.

#+BEGIN_SRC yaml :tangle ../triage/eis_crosstabs_config.yaml
output:
  schema: 'test_results'
  table: 'eis_crosstabs_test'

thresholds:
    rank_abs: [50]
    rank_pct: [5]

#(optional): a list of entity_ids to subset on the crosstabs analysis
entity_id_list: []

models_list_query: "select unnest(ARRAY[174, 178]) :: int as model_id"

as_of_dates_query: "select unnest(ARRAY['2016-12-01']) :: date as as_of_date"

#don't change this query unless strictly necessary. It is just validating pairs of (model_id,as_of_date)
#it is just a join with distinct (model_id, as_of_date) in a predictions table
models_dates_join_query: |
  select model_id,
  as_of_date
  from models_list_query as m
  cross join as_of_dates_query a join (select distinct model_id, as_of_date from test_results.predictions) as p
  using (model_id, as_of_date)

#features_query must join models_dates_join_query with 1 or more features table using as_of_date
features_query: |
  select m.model_id, f1.*
  from features.inspections_aggregation_imputed as f1 join
  models_dates_join_query as m using (as_of_date)

#the predictions query must return model_id, as_of_date, entity_id, score, label_value, rank_abs and rank_pct
#it must join models_dates_join_query using both model_id and as_of_date
predictions_query: |
  select model_id,
      as_of_date,
      entity_id,
      score,
      label_value,
      coalesce(rank_abs, row_number() over (partition by (model_id, as_of_date) order by score desc)) as rank_abs,
      coalesce(rank_pct*100, ntile(100) over (partition by (model_id, as_of_date) order by score desc)) as rank_pct
      from test_results.predictions
      join models_dates_join_query USING(model_id, as_of_date)
      where model_id IN (select model_id from models_list_query)
      and as_of_date in (select as_of_date from as_of_dates_query)
#+END_SRC


#+BEGIN_SRC sh :dir /docker:root@tutorial_bastion:/triage :exports code
triage --tb crosstabs eis_crosstabs_config.yaml
:
#+END_SRC

#+RESULTS:
#+BEGIN_SRC org
/usr/local/lib/python3.6/site-packages/psycopg2/__init__.py:144: UserWarning: The psycopg2 wheel package will be renamed from release 2.8; in order to keep installing from binary please use "pip install psycopg2-binary" instead. For details see: <http://initd.org/psycopg/docs/install.html#binary-install-from-pypi>.
  """)
Traceback (most recent call last):
  File "/usr/local/bin/triage", line 11, in <module>
    load_entry_point('triage==3.3.0', 'console_scripts', 'triage')()
  File "/usr/local/lib/python3.6/site-packages/triage/cli.py", line 415, in execute
    main(Triage)
  File "/usr/local/lib/python3.6/site-packages/argcmdr.py", line 70, in main
    command.call(args)
  File "/usr/local/lib/python3.6/site-packages/argcmdr.py", line 310, in call
    return target_callable(*call_args[:param_count])
  File "/usr/local/lib/python3.6/site-packages/triage/cli.py", line 379, in __call__
    config_store = Store.factory(args.config)
  File "/usr/local/lib/python3.6/site-packages/triage/component/catwalk/storage.py", line 48, in factory
    return FSStore(*pathparts)
  File "/usr/local/lib/python3.6/site-packages/triage/component/catwalk/storage.py", line 144, in __init__
    os.makedirs(dirname(self.path), exist_ok=True)
  File "/usr/local/lib/python3.6/os.py", line 220, in makedirs
    mkdir(name, mode)
FileNotFoundError: [Errno 2] No such file or directory: ''
[0m
#+END_SRC
