#+STARTUP: showeverything
#+STARTUP: nohideblocks
#+STARTUP: indent
#+PROPERTY: header-args:sql :engine postgresql
#+PROPERTY: header-args:sql+ :dbhost 0.0.0.0
#+PROPERTY: header-args:sql+ :dbport 5434
#+PROPERTY: header-args:sql+ :dbuser food_user
#+PROPERTY: header-args:sql+ :dbpassword some_password
#+PROPERTY: header-args:sql+ :database food
#+PROPERTY: header-args:sql+ :results table drawer
#+PROPERTY: header-args:ipython   :session :exports both :results raw drawer
#+PROPERTY: header-args:python    :session food_inspections :results output Drawer
#+PROPERTY: header-args:sh  :results verbatim org
# +PROPERTY: header-args:sh+ :prologue exec 2>&1 :epilogue :
#+PROPERTY: header-args:sh+  :dir ..

* Inpection prioritization
** Problem description

 We will begin with the *inspection prioritization* problem, where we want to generate a list of
   facilities that will have a *critical* or *serious* food violation /if/ inspected.

The scenario is the following: you work for the City of Chicago and you have
  limited food inspectors, so you try to prioritize them to focus on the highest-risk
  facilities. So you will use the data to answer the next question:

#+begin_quote
Which X facilities are most likely to fail a food inspection in the
  following Y period of time?
#+end_quote

If you want to focus on major violations only, you can do that too:

#+begin_quote
Which X facilities are most likely to have a critical or serious
  violation in the following Y period of time?
#+end_quote


** Creating the labels

We will define two labels:

- *Which facilities are likely to fail an inspection?*

The label takes a 1 if the inspection had at least one =result= = ='fail'= and a 0 otherwise.

- *Which facilities fail an inspection with a major violation?*

Critical violations are coded between =1-14=, serious violations between
=15-29=, everything above =30= is assumed to be a minor violation.
The label takes a 1 if the inspection had at least one =result= = ='fail'= and a
violation between 1 and 29, and a 0 otherwise.

We can extract the severity of the violation using the
following code:


#+begin_src sql
select
event_id,
date,
result,
array_agg(obj ->>'severity') as violations_severity,
(result = 'fail') as failed,
(result = 'fail' and
('serious' = ANY(array_agg(obj ->> 'severity')) or 'critical' = ANY(array_agg(obj ->> 'severity')))
) as failed_major_violation
from
(select event_id, date, result, jsonb_array_elements(violations::jsonb) as obj from semantic.events limit 20)
as t1
group by event_id, date, result
order by date desc

#+end_src

#+RESULTS:
:RESULTS:
| event_id |       date | result | violations_severity                                       | failed | failed_major_violation |
|---------+------------+--------+----------------------------------------------------------+--------+----------------------|
| 1770568 | 2016-05-11 | pass   | {critical,minor,minor,serious,serious}                   | f      | f                    |
| 1763967 | 2016-05-03 | fail   | {minor,critical,serious,serious,minor,minor,minor,minor} | t      | t                    |
| 1343315 | 2013-06-06 | fail   | {minor,serious,serious,serious,serious,minor}            | t      | t                    |
|  537439 | 2011-06-10 | fail   | {NULL}                                                   | t      | [NULL]               |
:END:

Remember from [[A tale of two tables]] that the /outcome/ will be used by
=triage= to generate the labels. The following image tries to
show the meaning of the /outcomes/ for the /inspection failed/ problem definition.

#+NAME: fig:outcomes-inspections
#+CAPTION: The image shows three facilities and, next to each, a temporal line with 6 days (0-5). Each dot represents an inspection. Green means the facility passed the inspection, and red means it failed. Each facility in the image had two inspections, but only the facility in the middle passed both.
#+ATTR_ORG: :width 600 :height 400
#+ATTR_HTML: :width 600 :height 600
#+ATTR_LATEX: :width 400 :height 300
[[./images/outcomes-inspections.png]]



** Modeling Using Machine Learning

It is time to put these steps together. All the coding is complete;
we just need to modify the =triage= configuration file.

*** Creating a simple experiment

For the first experiment we will try one of the simplest
machine learning algorithms: a *Decision Tree Classifier* (/DT/)
The rationale of this is that the DT is very fast to train (so it will
help us to verify that the experiment configuration is correct without
waiting for a long time) and it helps you
to understand the structure of your data. We will train a DT with only
one split (i.e. one level of depth) and one full growth.
We need to write the experiment config file for that. Let's break it
down and explain the sections.


The config file for this first experiment is located in
[[./triage/experiment_config/inspections_dt.yaml]]


The first lines of the experiment config file specify the
config-file version (=v5= at the moment of writing this tutorial),
a comment (=model_comment=, which will end up as
a value in the =results.models= table), and a list of user-defined
metadata (=user_metadata=) that can identify the
resulting model groups. For this example, if you run experiments that share
a temporal configuration but that use different label definitions
(say, labeling inspections with *any* violation as positive versus
only labeling inspections with major violations as positive),
you can use the user metadata keys to indicate that the matrices
from these experiments have different labeling criteria. The matrices from the
two experiments will have different filenames (and should not be overwritten or
incorrectly used), and if you add the =label_definition= key to
the =model_group_keys=, models made on different label definitions will
belong to different model groups.

#+BEGIN_SRC yaml :tangle ../triage/experiment_config/inspections_dt.yaml
config_version: 'v5'

model_comment: 'inspections_dt'

user_metadata:
  label_definition: 'failed'
  experiment_type: 'inspections prioritization'
  description: |
    Decision Tree Classifier
  purpose: 'test'
  org: 'DSaPP'
  team: 'Tutorial'
  author: 'Your name here'
#+END_SRC

Next comes the *temporal configuration* section. The first four parameters
are related to the availability of data: How much data you have for
feature creation? How much data you have for label generation? For
simplicity we will assume that we can use the full =semantic.events= time
span for both.

#+BEGIN_SRC sql
select min(date), max(date) from semantic.events
#+END_SRC

#+RESULTS:
:RESULTS:
|        min |        max |
|------------+------------|
| 2010-01-04 | 2018-05-21 |
:END:

The next parameters are related to the training intervals:
- How frequently to retrain models? (=model_update_frequency=)
- How many rows per entity in the train matrices?
  (=training_as_of_date_frequencies=)
- How much time is covered by labels in the training matrices? (=training_label_timespans=)

The remaining elements are related to the *testing* matrices.
For *inspections*, you can choose them as follows:

- =test_as_of_date_frequencies= is planning/scheduling frequency
- =test_durations= how far ahead do you schedule inspections?
- =test_label_timespan= is equal to =test_durations=

Let's assume that we need to do rounds of inspections every month
(=test_as_of_date_frequencies = 1month=) and we need to complete that
round in exactly one month (=test_durations = test_label_timespan =
1month=)

#+BEGIN_SRC yaml :tangle ../triage/experiment_config/inspections_dt.yaml
temporal_config:
    feature_start_time: '2010-01-04'
    feature_end_time: '2018-03-01'
    label_start_time: '2015-02-01'
    label_end_time: '2018-03-01'

    model_update_frequency: '1y'
    training_label_timespans: ['1month']
    training_as_of_date_frequencies: '1month'

    test_durations: '1month'
    test_label_timespans: ['1month']
    test_as_of_date_frequencies: '1month'

    max_training_histories: '5y'
#+END_SRC

We can visualize the splitting using the function =show-timechop=
introduced in [[file:triage_intro.org][Introduction to triage]].

#+BEGIN_SRC sh

# Remember to run this in your laptop NOT in bastion!

./tutorial.sh triage --config_file inspections_dt.yaml show-temporal-blocks
#+END_SRC

#+RESULTS:
#+BEGIN_SRC org
Using the config file /triage/experiment_config/inspections_dt.yaml
The output (matrices and models) of this experiment will be stored in triage/output
Using data stored in postgresql://food_user:some_password@food_db/food
The experiment will use any preexisting matrix or model: False
Creating experiment object
Experiment loaded
Generating temporal blocks image
Image stored in:
/triage/output/images/inspections_dt.svg
#+End_src

#+CAPTION: Temporal blocks for inspections_dt experiment
#+ATTR_ORG: :width 600 :height 400
#+ATTR_HTML: :width 800 :height 800
#+ATTR_LATEX: :width 400 :height 300
[[./images/inspections_dt.png]]

We need to specify the table that keeps our labels. For this first
experiment we will use the label =failed=, using the query from the
previous section

#+BEGIN_SRC yaml :tangle ../triage/experiment_config/inspections_dt.yaml
label_config:
  query: |
    select
    entity_id,
    bool_or(result = 'fail')::integer as outcome
    from semantic.events
    where '{as_of_date}'::timestamp <= date
    and date < '{as_of_date}'::timestamp + interval '{label_timespan}'
    group by entity_id
  #include_missing_labels_in_train_as: False
  name: 'failed_inspection'
#+END_SRC

We just want to include *active* facilities in our matrices, so we tell
=triage= to take that in account:

#+BEGIN_SRC yaml :tangle ../triage/experiment_config/inspections_dt.yaml
cohort_config:
  query: |
    select entity_id
    from semantic.entities
    where
    tsrange(start_time, end_time, '[]') @> {as_of_date}
  name: 'active_facilities'
#+END_SRC



=Triage= will generate the features for us, but we need to tell it which features
we want in the section =feature_aggregations=. Here, each entry describes a
=collate.SpacetimeAggregation= object and the
arguments needed to create it. For this experiment we will try the following
features:

- Number of different types of inspections the facility had in the last year
  (calculated for an as-of date).
-
- Number of different types of inspections that happened in the
  zip code in the last year from a particular day.

If we observe the image generated from the =temporal_config= section,
each particular date is the beginning of the rectangles that describes
the rows in the matrix. In that date (=as_of_date= in =timechop= parlance)
we will calculate both features, and we will repeat that for every
other rectangle in that image.

#+BEGIN_SRC yaml :tangle ../triage/experiment_config/inspections_dt.yaml
feature_aggregations:
    -
        prefix: 'inspections'
        from_obj: 'semantic.events'
        knowledge_date_column: 'date'

        categoricals_imputation:
            all:
                type: 'zero'

        categoricals:
            -
                column: 'type'
                choice_query: 'select distinct type from semantic.events where type is not null'
                metrics:
                    - 'sum'

        intervals:
            - '3month'

        groups:
            - 'entity_id'
            - 'zip_code'
#+END_SRC


Now, let's discuss how we will specify the models to try
(remember that the model is specified by the algorithm, the
hyperparameters, and the subset of features to use). In =triage= you
need to specify in the =grid_config= section a list of machine learning
algorithms that you want to train and a list of
hyperparameters. You can use any algorithm that you want; the only
requirement is that it respects the =sklearn= API.


#+BEGIN_SRC yaml :tangle ../triage/experiment_config/inspections_dt.yaml
grid_config:
    'sklearn.tree.DecisionTreeClassifier':
        max_depth: [1,null]
        max_features: [1, sqrt, null]
#+END_SRC

Some of the parameters in =sklearn= are =None=. If you want to try those
you need to indicate it with =yaml='s =null= keyword.

Besides the algorithm and the hyperparameters, you should specify
which subset of features use. First, in the section
=feature_group_definition= you specify how to group the features (you
can use the =table name= or the =prefix= from the section
=feature_aggregation=) and then a /strategy/ for choosing the
subsets: =all= (all the subsets at once), =leave-one-out= (try all the
subsets except one, do that for all the combinations), or =leave-one-in=
(just try subset at the time).


#+BEGIN_SRC yaml :tangle ../triage/experiment_config/inspections_dt.yaml
feature_group_definition:
   prefix: ['inspections']

feature_group_strategies: ['all']
#+END_SRC

In this experiment we will end with *6* model groups ($algorithms (1) \times
hyperparameters combinations (2 \times 3)  \times feature groups (1) \times temporal
combinations (1)$). Also, we will create *12* models (2 per
model group) given that we have 2 temporal blocks (one model per
temporal group).


Finally, we should define wich metrics we care about for evaluating our
model. Here we will concentrate only in =precision= and =recall=.

#+BEGIN_SRC yaml :tangle ../triage/experiment_config/inspections_dt.yaml
scoring:
    sort_seed: 5
    testing_metric_groups:
        -
          metrics: [precision@, recall@]
          thresholds:
            percentiles: [5.0, 10.0]
            top_n: [5, 10, 25]

    training_metric_groups:
      -
        metrics: [accuracy]
      -
        metrics: [precision@, recall@]
        thresholds:
          percentiles: [5.0, 10.0]
          top_n: [5, 10, 25]

#+END_SRC

You should be warned that precision and recall at $k$ in this setting
is kind of ill-defined (because you will end with a lot of =NULL=
labels, remember, only a few of facilities are inspected in each
period).

We will want a *list* of facilities to
be inspected. The length of our list is constrained by our inspection
resources, i.e. the answer to the question /How many facilities can I
inpect in a month?/ In this experiment we are assuming that the
maximum capacity is *25* but we are testing also for a list of length
*5*, and *10* (see =top_n= above).

The execution of the experiments can take a long time, so it is a
good practice to /validate/ the configuration file /before/ running
the model. You don't want to wait for hours (or days) and then
discover that something went wrong.

#+BEGIN_SRC sh
./tutorial.sh triage --config_file inspections_dt.yaml validate
#+END_SRC

#+RESULTS:
#+BEGIN_SRC org
Using the config file /triage/experiment_config/inspections_dt.yaml
The output (matrices and models) of this experiment will be stored in triage/output
Using data stored in postgresql://food_user:some_password@food_db/food
The experiment will utilize any preexisting matrix or model: False
Creating experiment object
Experiment loaded
Validating experiment's configuration
Experiment validation ran to completion with no errors

----TIME SPLIT SUMMARY----

Number of time splits: 3
Split index 0:
            Training as_of_time_range: 2015-02-01 00:00:00 to 2015-12-01 00:00:00 (11 total)
            Testing as_of_time range: 2016-01-01 00:00:00 to 2016-01-01 00:00:00 (1 total)


Split index 1:
            Training as_of_time_range: 2015-02-01 00:00:00 to 2016-12-01 00:00:00 (23 total)
            Testing as_of_time range: 2017-01-01 00:00:00 to 2017-01-01 00:00:00 (1 total)


Split index 2:
            Training as_of_time_range: 2015-02-01 00:00:00 to 2017-12-01 00:00:00 (35 total)
            Testing as_of_time range: 2018-01-01 00:00:00 to 2018-01-01 00:00:00 (1 total)


For more detailed information on your time splits, inspect the experiment `split_definitions` property

           The experiment configuration doesn't contain any obvious errors.
           Any error that occurs from now on, possibly will be related to hit the maximum
           number of columns allowed or collision in
           the column names, both due to PostgreSQL limitations.

The experiment looks in good shape. May the force be with you
#+END_SRC

You can execute the experiment as

#+BEGIN_SRC sh
./tutorial.sh triage --config_file inspections_dt.yaml run
#+END_SRC

#+RESULTS:
#+BEGIN_SRC org
Using the config file /triage/experiment_config/inspections_dt.yaml
The output (matrices and models) of this experiment will be stored in triage/output
Using data stored in postgresql://food_user:some_password@food_db/food
The experiment will utilize any preexisting matrix or model: False
Creating experiment object
Experiment loaded
Executing experiment
Done
Experiment completed in 0:03:17.957022 seconds
#+END_SRC

This will print a lot of output, and if everything is correct it will
create 6 matrices (3 for
training, 3 for testing) in =triage/matrices= and every matrix will be
represented by two files, one with the metadata of the matrix (a
=yaml= file) and one with the actual matrix (the =csv= file).

#+BEGIN_SRC sh :dir /docker:root@tutorial_bastion:/ :results raw drawer
ls /triage/output/matrices | awk -F . '{print $NF}' | sort | uniq -c
#+END_SRC

#+Results:
:RESULTS:
      6 csv
      6 yaml
:END:

=Triage= also will store 18 trained models in =triage/trained_models=:

#+BEGIN_SRC sh :dir /docker:root@tutorial_bastion:/ :results raw drawer
ls /triage/output/trained_models | wc -l
#+END_SRC

#+RESULTS:
:RESULTS:
18
:END:

And it will populate the =results= schema in the database. As
mentioned, we will get =6= /model groups/:

#+BEGIN_SRC sql
select model_group_id, model_type, hyperparameters from model_metadata.model_groups;
#+END_SRC

#+RESULTS:
:RESULTS:
| model_group_id | model_type                           | hyperparameters                           |
|--------------+-------------------------------------+-------------------------------------------|
|            1 | sklearn.tree.DecisionTreeClassifier | {"max_depth": 1, "max_features": 1}         |
|            2 | sklearn.tree.DecisionTreeClassifier | {"max_depth": 1, "max_features": "sqrt"}    |
|            3 | sklearn.tree.DecisionTreeClassifier | {"max_depth": 1, "max_features": null}      |
|            4 | sklearn.tree.DecisionTreeClassifier | {"max_depth": null, "max_features": 1}      |
|            5 | sklearn.tree.DecisionTreeClassifier | {"max_depth": null, "max_features": "sqrt"} |
|            6 | sklearn.tree.DecisionTreeClassifier | {"max_depth": null, "max_features": null}   |
:END:

And =18= /models/:


#+BEGIN_SRC sql
select
model_group_id, model_id, train_end_time
from model_metadata.models
order by model_group_id, train_end_time asc
#+END_SRC

#+RESULTS:
:RESULTS:
| model_group_id | model_id | train_end_time        |
|--------------+---------+---------------------|
|            1 |       1 | 2016-01-01 00:00:00 |
|            1 |       7 | 2017-01-01 00:00:00 |
|            1 |      13 | 2018-01-01 00:00:00 |
|            2 |       2 | 2016-01-01 00:00:00 |
|            2 |       8 | 2017-01-01 00:00:00 |
|            2 |      14 | 2018-01-01 00:00:00 |
|            3 |       3 | 2016-01-01 00:00:00 |
|            3 |       9 | 2017-01-01 00:00:00 |
|            3 |      15 | 2018-01-01 00:00:00 |
|            4 |       4 | 2016-01-01 00:00:00 |
|            4 |      10 | 2017-01-01 00:00:00 |
|            4 |      16 | 2018-01-01 00:00:00 |
|            5 |       5 | 2016-01-01 00:00:00 |
|            5 |      11 | 2017-01-01 00:00:00 |
|            5 |      17 | 2018-01-01 00:00:00 |
|            6 |       6 | 2016-01-01 00:00:00 |
|            6 |      12 | 2017-01-01 00:00:00 |
|            6 |      18 | 2018-01-01 00:00:00 |
:END:

From that last query, you should note that the order in which =triage= trains
the models is from oldest to newest =train_end_time= and
=model_group= , also in ascending order. It will not go to the
next block until all the /models groups/ are trained.

You can check with which matrix the models are trained:

#+NAME: train_info
#+BEGIN_SRC sql
select
model_id, model_group_id, train_end_time,
model_hash, train_matrix_uuid,
ma.num_observations as observations,
ma.lookback_duration as feature_lookback_duration,  ma.feature_start_time
from model_metadata.models as mo
join model_metadata.matrices as ma on train_matrix_uuid = matrix_uuid
order by model_group_id, train_end_time asc
#+End_SRC

#+RESULTS: train_info
:RESULTS:
| model_id | model_group_id | train_end_time        | model_hash                        | train_matrix_uuid                  | observations | feature_lookback_duration | feature_start_time    |
|---------+--------------+---------------------+----------------------------------+----------------------------------+--------------+-------------------------+---------------------|
|       1 |            1 | 2016-01-01 00:00:00 | b8760f6ff91cf67a7e13ddde9a6ebc02 | ff127360d74ed8ec4fcf2bcb21a9ebb4 |        11669 | 5 years                 | 2010-01-04 00:00:00 |
|       7 |            1 | 2017-01-01 00:00:00 | 8b52fd95a5a95de85a0e686eefb9f321 | c03aaa4812cf316a933c9d1da1c9ade6 |        26018 | 5 years                 | 2010-01-04 00:00:00 |
|      13 |            1 | 2018-01-01 00:00:00 | 76e6eafed233e035ebec64802a367f5a | f8cf102711b7162ef7d1780613d52f0d |        39394 | 5 years                 | 2010-01-04 00:00:00 |
|       2 |            2 | 2016-01-01 00:00:00 | 50c082cdcda8032066324d2b512b6ecd | ff127360d74ed8ec4fcf2bcb21a9ebb4 |        11669 | 5 years                 | 2010-01-04 00:00:00 |
|       8 |            2 | 2017-01-01 00:00:00 | dca1e0f675b28dccdb21ccf0b0caa6ff | c03aaa4812cf316a933c9d1da1c9ade6 |        26018 | 5 years                 | 2010-01-04 00:00:00 |
|      14 |            2 | 2018-01-01 00:00:00 | b88f85a042a9291b7c6ba4e4b6ddfc9c | f8cf102711b7162ef7d1780613d52f0d |        39394 | 5 years                 | 2010-01-04 00:00:00 |
|       3 |            3 | 2016-01-01 00:00:00 | 3693b4df0280b6b7f92d843839fb90af | ff127360d74ed8ec4fcf2bcb21a9ebb4 |        11669 | 5 years                 | 2010-01-04 00:00:00 |
|       9 |            3 | 2017-01-01 00:00:00 | df0ba21bb46d690ac9894d5efd28be26 | c03aaa4812cf316a933c9d1da1c9ade6 |        26018 | 5 years                 | 2010-01-04 00:00:00 |
|      15 |            3 | 2018-01-01 00:00:00 | 62d1a0ed5b58c42c2bb062ac35145043 | f8cf102711b7162ef7d1780613d52f0d |        39394 | 5 years                 | 2010-01-04 00:00:00 |
|       4 |            4 | 2016-01-01 00:00:00 | 5a2767ae9d4c0b4c107e86b44700ca88 | ff127360d74ed8ec4fcf2bcb21a9ebb4 |        11669 | 5 years                 | 2010-01-04 00:00:00 |
|      10 |            4 | 2017-01-01 00:00:00 | 845803b72bc3e9f283fc59946b971f24 | c03aaa4812cf316a933c9d1da1c9ade6 |        26018 | 5 years                 | 2010-01-04 00:00:00 |
|      16 |            4 | 2018-01-01 00:00:00 | 4b9c95c7c5d79ab7d427c9c0dea7b96b | f8cf102711b7162ef7d1780613d52f0d |        39394 | 5 years                 | 2010-01-04 00:00:00 |
|       5 |            5 | 2016-01-01 00:00:00 | 2f6dd475af37e7c34ec9db4df177ecfd | ff127360d74ed8ec4fcf2bcb21a9ebb4 |        11669 | 5 years                 | 2010-01-04 00:00:00 |
|      11 |            5 | 2017-01-01 00:00:00 | c0cd05226aca63b1e69c8a684e20f647 | c03aaa4812cf316a933c9d1da1c9ade6 |        26018 | 5 years                 | 2010-01-04 00:00:00 |
|      17 |            5 | 2018-01-01 00:00:00 | b19f971d62806556bb8fb8f32ed38bbb | f8cf102711b7162ef7d1780613d52f0d |        39394 | 5 years                 | 2010-01-04 00:00:00 |
|       6 |            6 | 2016-01-01 00:00:00 | 3c48165e4b8edf45d00030c8835ad423 | ff127360d74ed8ec4fcf2bcb21a9ebb4 |        11669 | 5 years                 | 2010-01-04 00:00:00 |
|      12 |            6 | 2017-01-01 00:00:00 | 4aafe62f79ef54e01d7b9c15640dc7e6 | c03aaa4812cf316a933c9d1da1c9ade6 |        26018 | 5 years                 | 2010-01-04 00:00:00 |
|      18 |            6 | 2018-01-01 00:00:00 | 6663e0c150f5c160f74c722b697dc4bd | f8cf102711b7162ef7d1780613d52f0d |        39394 | 5 years                 | 2010-01-04 00:00:00 |
:END:

As expected, we have three models per model group. Each model was trained
with the matrix indicated in the column =train_matrix_uuid=. This =uuid=
is the file name of the stored matrix. The model itself was
stored under the file named with the =model_hash=.

If you want to see in which matrix the model was /tested/ you need to
run the following query

#+NAME: test_info
#+BEGIN_SRC  sql
select distinct
model_id,
model_group_id, train_end_time,
model_hash,
pr.matrix_uuid as test_matrix_uuid,
ma.num_observations as observations,
ma.lookback_duration as feature_lookback_duration,  ma.feature_start_time
from model_metadata.models as mo
join test_results.predictions as pr using (model_id)
join model_metadata.matrices as ma on pr.matrix_uuid = ma.matrix_uuid
order by model_group_id, train_end_time asc
#+END_SRC

#+RESULTS: test_info
:RESULTS:
| model_id | model_group_id | train_end_time        | model_hash                        | test_matrix_uuid                   | observations | feature_lookback_duration | feature_start_time    |
|---------+--------------+---------------------+----------------------------------+----------------------------------+--------------+-------------------------+---------------------|
|       1 |            1 | 2016-01-01 00:00:00 | b8760f6ff91cf67a7e13ddde9a6ebc02 | 8c9404c0189bd4db3bacc104e37df218 |        18728 | 1 mon                   | 2010-01-04 00:00:00 |
|       7 |            1 | 2017-01-01 00:00:00 | 8b52fd95a5a95de85a0e686eefb9f321 | da117a585bd31867a92921e53fe180e9 |        19401 | 1 mon                   | 2010-01-04 00:00:00 |
|      13 |            1 | 2018-01-01 00:00:00 | 76e6eafed233e035ebec64802a367f5a | e1686b2692789dc808e59d50e2d3a595 |        20171 | 1 mon                   | 2010-01-04 00:00:00 |
|       2 |            2 | 2016-01-01 00:00:00 | 50c082cdcda8032066324d2b512b6ecd | 8c9404c0189bd4db3bacc104e37df218 |        18728 | 1 mon                   | 2010-01-04 00:00:00 |
|       8 |            2 | 2017-01-01 00:00:00 | dca1e0f675b28dccdb21ccf0b0caa6ff | da117a585bd31867a92921e53fe180e9 |        19401 | 1 mon                   | 2010-01-04 00:00:00 |
|      14 |            2 | 2018-01-01 00:00:00 | b88f85a042a9291b7c6ba4e4b6ddfc9c | e1686b2692789dc808e59d50e2d3a595 |        20171 | 1 mon                   | 2010-01-04 00:00:00 |
|       3 |            3 | 2016-01-01 00:00:00 | 3693b4df0280b6b7f92d843839fb90af | 8c9404c0189bd4db3bacc104e37df218 |        18728 | 1 mon                   | 2010-01-04 00:00:00 |
|       9 |            3 | 2017-01-01 00:00:00 | df0ba21bb46d690ac9894d5efd28be26 | da117a585bd31867a92921e53fe180e9 |        19401 | 1 mon                   | 2010-01-04 00:00:00 |
|      15 |            3 | 2018-01-01 00:00:00 | 62d1a0ed5b58c42c2bb062ac35145043 | e1686b2692789dc808e59d50e2d3a595 |        20171 | 1 mon                   | 2010-01-04 00:00:00 |
|       4 |            4 | 2016-01-01 00:00:00 | 5a2767ae9d4c0b4c107e86b44700ca88 | 8c9404c0189bd4db3bacc104e37df218 |        18728 | 1 mon                   | 2010-01-04 00:00:00 |
|      10 |            4 | 2017-01-01 00:00:00 | 845803b72bc3e9f283fc59946b971f24 | da117a585bd31867a92921e53fe180e9 |        19401 | 1 mon                   | 2010-01-04 00:00:00 |
|      16 |            4 | 2018-01-01 00:00:00 | 4b9c95c7c5d79ab7d427c9c0dea7b96b | e1686b2692789dc808e59d50e2d3a595 |        20171 | 1 mon                   | 2010-01-04 00:00:00 |
|       5 |            5 | 2016-01-01 00:00:00 | 2f6dd475af37e7c34ec9db4df177ecfd | 8c9404c0189bd4db3bacc104e37df218 |        18728 | 1 mon                   | 2010-01-04 00:00:00 |
|      11 |            5 | 2017-01-01 00:00:00 | c0cd05226aca63b1e69c8a684e20f647 | da117a585bd31867a92921e53fe180e9 |        19401 | 1 mon                   | 2010-01-04 00:00:00 |
|      17 |            5 | 2018-01-01 00:00:00 | b19f971d62806556bb8fb8f32ed38bbb | e1686b2692789dc808e59d50e2d3a595 |        20171 | 1 mon                   | 2010-01-04 00:00:00 |
|       6 |            6 | 2016-01-01 00:00:00 | 3c48165e4b8edf45d00030c8835ad423 | 8c9404c0189bd4db3bacc104e37df218 |        18728 | 1 mon                   | 2010-01-04 00:00:00 |
|      12 |            6 | 2017-01-01 00:00:00 | 4aafe62f79ef54e01d7b9c15640dc7e6 | da117a585bd31867a92921e53fe180e9 |        19401 | 1 mon                   | 2010-01-04 00:00:00 |
|      18 |            6 | 2018-01-01 00:00:00 | 6663e0c150f5c160f74c722b697dc4bd | e1686b2692789dc808e59d50e2d3a595 |        20171 | 1 mon                   | 2010-01-04 00:00:00 |
:END:

For example, the model =7= was stored as
=/triage/trained_models/8b52fd95a5a95de85a0e686eefb9f321=
using the standard serialization of sklearn models. This model was
trained with the matrix =c03aaa4812cf316a933c9d1da1c9ade6=
 stored in the directory =/triage/matrices=.

Model =7= used the following hyperparameters:

#+BEGIN_SRC sql
select
hyperparameters
from model_metadata.models
where model_id = 7
#+END_SRC

#+RESULTS:
:RESULTS:
| hyperparameters                   |
|-----------------------------------|
| {"max_depth": 1, "max_features": 1} |
:END:


We can visualize the model

#+BEGIN_SRC sh
./tutorial.sh triage --config_file inspections_dt.yaml show_model_plot --model 7
#+END_SRC

#+RESULTS:
#+BEGIN_SRC org
Using the config file /triage/experiment_config/inspections_baseline.yaml
The output (matrices and models) of this experiment will be stored in triage/output
Using data stored in postgresql://food_user:some_password@food_db/food
The experiment will utilize any preexisting matrix or model: False
Creating experiment object
Experiment loaded
Generating model image
Plotting tree number 0
Image stored in:
['/triage/output/images/model_7_tree_0.svg']
#+End_src

#+CAPTION: Graphical representation of the trained model no.3: Decision Tree Classifier (max_depth:1, max_features:1)
#+ATTR_ORG: :width 600 :height 400
#+ATTR_HTML: :width 400 :height 300
#+ATTR_LATEX: :width 400 :height 300
[[./images/model_7_tree_0.png]]


We can also get information about the /model group/:

#+BEGIN_SRC sql
select
--model_group_id, model_type,
jsonb_pretty(model_config) as model_config, model_group_id, model_type
from
model_metadata.model_groups
where model_group_id = 1
#+END_SRC

#+RESULTS:
:RESULTS:
| model_config                       | model_group_id | model_type                           |
|-----------------------------------+--------------+-------------------------------------|
| {                                 |              |                                     |
| "state": "active",                |              |                                     |
| "label_name": "failed_inspection",  |              |                                     |
| "cohort_name": "active_facilities", |              |                                     |
| "feature_groups": [                |              |                                     |
| "prefix: inspections"             |              |                                     |
| ],                                |              |                                     |
| "label_timespan": "1month",        |              |                                     |
| "as_of_date_frequency": "1month",    |              |                                     |
| "max_training_history": "5y"        |              |                                     |
| }                                 |            1 | sklearn.tree.DecisionTreeClassifier |
:END:

The features used by that model are:

#+BEGIN_SRC sql
select
unnest(feature_list) as features
from
model_metadata.model_groups
where model_group_id = 1
#+END_SRC

#+RESULTS:
:RESULTS:
| features                                       |
|------------------------------------------------|
| inspections_entity_id_3month_type_canvass_sum        |
| inspections_entity_id_3month_type_complaint_sum      |
| inspections_entity_id_3month_type_consultation_sum   |
| inspections_entity_id_3month_type_food poisoning_sum |
| inspections_entity_id_3month_type_license_sum        |
| inspections_entity_id_3month_type__NULL_sum          |
| inspections_entity_id_3month_type_tag removal_sum    |
| inspections_entity_id_3month_type_task force_sum     |
| inspections_zip_code_3month_type_canvass_sum         |
| inspections_zip_code_3month_type_complaint_sum       |
| inspections_zip_code_3month_type_consultation_sum    |
| inspections_zip_code_3month_type_food poisoning_sum  |
| inspections_zip_code_3month_type_license_sum         |
| inspections_zip_code_3month_type__NULL_sum           |
| inspections_zip_code_3month_type_tag removal_sum     |
| inspections_zip_code_3month_type_task force_sum      |
:END:

Finally, the performance of the model =3=  are:

#+BEGIN_SRC sql
select
model_id,
metric || parameter as metric,
value,
num_labeled_examples,
num_labeled_above_threshold,
num_positive_labels
from test_results.evaluations where model_id = 7
order by num_labeled_above_threshold asc,
metric || parameter
#+END_SRC

#+RESULTS:
:RESULTS:
| model_id | metric            |               value | num_labeled_examples | num_labeled_above_threshold | num_positive_labels |
|---------+-------------------+---------------------+--------------------+--------------------------+-------------------|
|       7 | precision@10_abs   |                 0.0 |               1174 |                        0 |               269 |
|       7 | precision@5_abs    |                 0.0 |               1174 |                        0 |               269 |
|       7 | recall@10_abs      |                 0.0 |               1174 |                        0 |               269 |
|       7 | recall@5_abs       |                 0.0 |               1174 |                        0 |               269 |
|       7 | precision@25_abs   |                 0.0 |               1174 |                        2 |               269 |
|       7 | recall@25_abs      |                 0.0 |               1174 |                        2 |               269 |
|       7 | precision@5.0_pct  |                0.25 |               1174 |                       56 |               269 |
|       7 | recall@5.0_pct     | 0.05204460966542751 |               1174 |                       56 |               269 |
|       7 | precision@10.0_pct |  0.2457627118644068 |               1174 |                      118 |               269 |
|       7 | recall@10.0_pct    | 0.10780669144981413 |               1174 |                      118 |               269 |
:END:

The columns =num_labeled_examples, num_labeled_above_threshold,
num_positive_labels= represent the number of selected entities on the
prediction date that are labeled (there are =1174= entities in the
test matrix with a label (=1= or =0=)), the
number of entities with a positive label above the threshold
(e.g. there is none entities with a positive label in the first 10
entities ordered by score) and the number of entities with positive labels among all the
labeled entities (=269= of =1174=) respectively. In
English, between the /as of date/ (=2017-01-01=) and one month later (until =2017-02-01=) there
were =1174=  facilities *inspected* and =269= of those inspections *failed*.



Let's assume this is our best model. Which 25 facilities does it think we should inspect?

#+BEGIN_SRC sql
select entity_id, as_of_date as marked_to_be_inspected_at,
score, label_value
from test_results.predictions
where model_id = 7
order by score desc
limit 25
#+END_SRC

#+RESULTS:
:RESULTS:
| entity_id | marked_to_be_inspected_at | score | label_value |
|----------+-----------------------+-------+------------|
|        1 | 2017-01-01 00:00:00   |  0.25 | [NULL]     |
|        4 | 2017-01-01 00:00:00   |  0.25 | [NULL]     |
|        2 | 2017-01-01 00:00:00   |  0.25 | [NULL]     |
|        6 | 2017-01-01 00:00:00   |  0.25 | [NULL]     |
|        7 | 2017-01-01 00:00:00   |  0.25 | [NULL]     |
|        8 | 2017-01-01 00:00:00   |  0.25 | [NULL]     |
|        9 | 2017-01-01 00:00:00   |  0.25 | [NULL]     |
|        5 | 2017-01-01 00:00:00   |  0.25 | [NULL]     |
|       11 | 2017-01-01 00:00:00   |  0.25 | [NULL]     |
|       13 | 2017-01-01 00:00:00   |  0.25 | [NULL]     |
|       14 | 2017-01-01 00:00:00   |  0.25 | [NULL]     |
|       15 | 2017-01-01 00:00:00   |  0.25 | [NULL]     |
|       16 | 2017-01-01 00:00:00   |  0.25 | [NULL]     |
|       19 | 2017-01-01 00:00:00   |  0.25 | [NULL]     |
|       20 | 2017-01-01 00:00:00   |  0.25 | [NULL]     |
|       21 | 2017-01-01 00:00:00   |  0.25 | [NULL]     |
|       10 | 2017-01-01 00:00:00   |  0.25 | [NULL]     |
|       23 | 2017-01-01 00:00:00   |  0.25 | [NULL]     |
|       25 | 2017-01-01 00:00:00   |  0.25 | [NULL]     |
|       27 | 2017-01-01 00:00:00   |  0.25 | [NULL]     |
|       28 | 2017-01-01 00:00:00   |  0.25 | [NULL]     |
|       29 | 2017-01-01 00:00:00   |  0.25 | [NULL]     |
|       30 | 2017-01-01 00:00:00   |  0.25 | [NULL]     |
|       31 | 2017-01-01 00:00:00   |  0.25 | [NULL]     |
|       32 | 2017-01-01 00:00:00   |  0.25 | [NULL]     |
:END:

*** Defining a baseline

As a second step, lets do an experiment that defines our
/baseline/. To achieve this, we will use a similar experiment
config file with the following changes:

#+BEGIN_EXAMPLE yaml
model_comment: 'inspections_baseline'

user_metadata:
  label_definition: 'failed'
  experiment_type: 'inspections prioritization'
  description: |
    Baseline calculation
  purpose: 'baseline'
  org: 'DSaPP'
  team: 'Tutorial'
  author: 'Your name here'

grid_config:
    'sklearn.dummy.DummyClassifier':
        strategy: [prior,uniform, most_frequent]

model_group_keys:
    - 'label_definition'
    - 'experiment_type'
    - 'purpose'
#+END_EXAMPLE

The complete file is in [[./triage/experiment_config/inspections_baseline.yaml][triage/experiment_config/inspections_baseline.yaml]].

If we execute this experiment, we will get 3 more model groups (one
for each strategy) and 6 corresponding models (2 per
model group).

#+BEGIN_SRC sh
./tutorial.sh triage --config_file inspections_baseline.yaml validate
#+END_SRC

#+RESULTS:
#+BEGIN_SRC org
Using the config file /triage/experiment_config/inspections_baseline.yaml
The output (matrices and models) of this experiment will be stored in triage/output
Using data stored in postgresql://food_user:some_password@food_db/food
The experiment will utilize any preexisting matrix or model: False
Creating experiment object
Experiment loaded
Validating experiment's configuration
Experiment validation ran to completion with no errors

----TIME SPLIT SUMMARY----

Number of time splits: 3
Split index 0:
            Training as_of_time_range: 2015-02-01 00:00:00 to 2015-12-01 00:00:00 (11 total)
            Testing as_of_time range: 2016-01-01 00:00:00 to 2016-01-01 00:00:00 (1 total)


Split index 1:
            Training as_of_time_range: 2015-02-01 00:00:00 to 2016-12-01 00:00:00 (23 total)
            Testing as_of_time range: 2017-01-01 00:00:00 to 2017-01-01 00:00:00 (1 total)


Split index 2:
            Training as_of_time_range: 2015-02-01 00:00:00 to 2017-12-01 00:00:00 (35 total)
            Testing as_of_time range: 2018-01-01 00:00:00 to 2018-01-01 00:00:00 (1 total)


For more detailed information on your time splits, inspect the experiment `split_definitions` property

           The experiment configuration doesn't contain any obvious errors.
           Any error that occurs from now on, possibly will be related to hit the maximum
           number of columns allowed or collision in
           the column names, both due to PostgreSQL limitations.

The experiment looks in good shape. May the force be with you
#+END_SRC

You can execute the experiment like this:

#+BEGIN_SRC sh
./tutorial.sh triage --config_file inspections_baseline.yaml run
#+END_SRC

#+RESULTS:
#+BEGIN_SRC org
Using the config file /triage/experiment_config/inspections_baseline.yaml
The output (matrices and models) of this experiment will be stored in triage/output
Using data stored in postgresql://food_user:some_password@food_db/food
The experiment will utilize any preexisting matrix or model: False
Creating experiment object
Experiment loaded
Executing experiment
Done
Experiment completed in 0:01:08.273220 seconds
#+END_SRC

After the experiment finishes, you will get 3 new =model_groups= (1 per strategy)

#+BEGIN_SRC sql
select model_group_id, model_type, hyperparameters
from model_metadata.model_groups;
#+END_SRC

#+RESULTS:
:RESULTS:
| model_group_id | model_type                           | hyperparameters                           |
|--------------+-------------------------------------+-------------------------------------------|
|            1 | sklearn.tree.DecisionTreeClassifier | {"max_depth": 1, "max_features": 1}         |
|            2 | sklearn.tree.DecisionTreeClassifier | {"max_depth": 1, "max_features": "sqrt"}    |
|            3 | sklearn.tree.DecisionTreeClassifier | {"max_depth": 1, "max_features": null}      |
|            4 | sklearn.tree.DecisionTreeClassifier | {"max_depth": null, "max_features": 1}      |
|            5 | sklearn.tree.DecisionTreeClassifier | {"max_depth": null, "max_features": "sqrt"} |
|            6 | sklearn.tree.DecisionTreeClassifier | {"max_depth": null, "max_features": null}   |
|            7 | sklearn.dummy.DummyClassifier       | {"strategy": "prior"}                     |
|            8 | sklearn.dummy.DummyClassifier       | {"strategy": "uniform"}                   |
|            9 | sklearn.dummy.DummyClassifier       | {"strategy": "most_frequent"}              |
:END:

#+BEGIN_SRC sql

with baseline as (
select model_id, model_group_id
from model_metadata.models
where model_type ~ 'DummyClassifier'
)

select
model_group_id, model_id, metric || parameter as metric,
value
from test_results.evaluations
inner join baseline using(model_id)
where
metric || parameter = 'precision@25_abs'
order by metric || parameter, model_id
#+END_SRC

#+RESULTS:
:RESULTS:
| model_group_id | model_id | metric          | value |
|--------------+---------+-----------------+-------|
|            7 |      19 | precision@25_abs |   0.0 |
|            8 |      20 | precision@25_abs |   0.0 |
|            9 |      21 | precision@25_abs |   0.0 |
|            7 |      22 | precision@25_abs |   0.0 |
|            8 |      23 | precision@25_abs |   0.0 |
|            9 |      24 | precision@25_abs |   0.0 |
|            7 |      25 | precision@25_abs |   0.5 |
|            8 |      26 | precision@25_abs |   0.5 |
|            9 |      27 | precision@25_abs |   0.5 |
:END:


*** A more advanced experiment

Ok, let's add a more complete experiment. First the usual generalities.
Note that we change =experiment_type=

#+BEGIN_SRC yaml :tangle ../triage/experiment_config/inspections_label_failed_01.yaml
config_version: 'v5'

model_comment: 'inspections'

user_metadata:
  label_definition: 'failed'
  experiment_type: 'inspections prioritization'
  description: |
    First experiment
  purpose: 'development'
  org: 'DSaPP'
  team: 'Tutorial'
  author: 'Your name here'
#+END_SRC

As before, =triage= needs special tables that specify /outcomes/ (that is, call
=events_table=) and /states/. These are the
same; we didn't change anything.

#+BEGIN_SRC yaml :tangle ../triage/experiment_config/inspections_label_failed_01.yaml
label_config:
  query: |
    select
    entity_id,
    bool_or(result = 'fail')::integer as outcome
    from semantic.events
    where '{as_of_date}'::timestamp <= date
    and date < '{as_of_date}'::timestamp + interval '{label_timespan}'
    group by entity_id
  #include_missing_labels_in_train_as: False
  name: 'failed_inspection'

cohort_config:
  query: |
    select entity_id
    from semantic.entities
    where
    tsrange(start_time, end_time, '[]') @> {as_of_date}
  name: 'active_facilities'
#+END_SRC

Neither to the temporal configuration:

#+BEGIN_SRC  yaml :tangle ../triage/experiment_config/inspections_label_failed_01.yaml
temporal_config:
    feature_start_time: '2010-01-04'
    feature_end_time: '2018-03-01'
    label_start_time: '2015-02-01'
    label_end_time: '2018-03-01'

    model_update_frequency: '1y'
    training_label_timespans: ['1month']
    training_as_of_date_frequencies: '1month'

    test_durations: '1month'
    test_label_timespans: ['1y'] #
    test_as_of_date_frequencies: '1month'

    max_training_histories: '10y'
#+END_SRC

#+BEGIN_SRC sh
./tutorial.sh triage --config_file inspections_label_failed_01.yaml show-temporal-blocks
#+END_SRC

#+RESULTS:
#+BEGIN_SRC org
Using the config file /triage/experiment_config/inspections_label_failed_01.yaml
The output (matrices and models) of this experiment will be stored in triage/output
Using data stored in postgresql://food_user:some_password@food_db/food
The experiment will utilize any preexisting matrix or model: False
Creating experiment object
Experiment loaded
Generating temporal blocks image
Image stored in:
/triage/output/images/inspections.svg
#+End_src

#+CAPTION: Temporal blocks for inspections experiment. The label is a failed inspection in the next month.
#+ATTR_ORG: :width 600 :height 400
#+ATTR_HTML: :width 800 :height 800
#+ATTR_LATEX: :width 400 :height 300
[[./images/inspections.png]]

The first big change is that we are adding 3 more /features groups/:
=inspections= (we already use this), =risks=, and =results=. Remember
that all this refers to events in the past, i.e. /How many times the facility was marked with high risk in the previous 3 Months?/,
/What is the average rate of failed inspections in the previous year?/

#+BEGIN_SRC yaml :tangle ../triage/experiment_config/inspections_label_failed_01.yaml
feature_aggregations:
    -
        prefix: 'inspections'
        from_obj: 'semantic.events'
        knowledge_date_column: 'date'

        categoricals_imputation:
            all:
                type: 'zero'

        categoricals:
            -
                column: 'type'
                choice_query: 'select distinct type from semantic.events'
                metrics:
                    - 'sum'
                    - 'avg'

        intervals:
            - '2y'
            - '1y'
            - '6month'
            - '3month'

        groups:
            - 'entity_id'
            - 'zip_code'

    -
        prefix: 'risks'
        from_obj: 'semantic.events'
        knowledge_date_column: 'date'

        categoricals_imputation:
            all:
                type: 'zero'

        categoricals:
            -
                column: 'risk'
                choice_query: 'select distinct risk from semantic.events'
                metrics:
                    - 'sum'
                    - 'avg'

        intervals:
            - '2y'
            - '1y'
            - '6month'
            - '3month'

        groups:
            - 'entity_id'
            - 'zip_code'
            - 'facility_type'


    -
        prefix: 'results'
        from_obj: 'semantic.events'
        knowledge_date_column: 'date'

        categoricals_imputation:
            all:
                type: 'zero'

        categoricals:
            -
                column: 'result'
                choice_query: 'select distinct result from semantic.events'
                metrics:
                    - 'sum'
                    - 'avg'

        intervals:
            - '2y'
            - '1y'
            - '6month'
            - '3month'

        groups:
            - 'entity_id'
            - 'zip_code'
            - 'facility_type'

#+END_Src

We want to use all the features groups
(=feature_group_definition=). The training will be made on matrices
with =all= the feature groups, then leaving one feature group out at a time,
=leave-one-out= (i.e. one model with =inspections= and =results=, another with
=inspections= and =risks=, and another with =results= and =risks), and finally
leaving one feature group in at a time (i.e. a model with =inspections= only,
another with =results= only, and a third with =risks= only).

#+BEGIN_SRC yaml :tangle ../triage/experiment_config/inspections_label_failed_01.yaml
feature_group_definition:
   prefix: ['inspections', 'results', 'risks']

feature_group_strategies: ['all', 'leave-one-in', 'leave-one-out']
#+END_SRC

Finally, we will try a =RandomForestClassifier=:


#+BEGIN_SRC yaml :tangle ../triage/experiment_config/inspections_label_failed_01.yaml
grid_config:
    'sklearn.ensemble.RandomForestClassifier':
        max_features: ['sqrt']
        criterion: ['gini']
        n_estimators: [1000]
        min_samples_leaf: [1]
        min_samples_split: [50]
        class_weight: ['balanced']

scoring:
    sort_seed: 1234
    testing_metric_groups:
        -
            metrics: ['precision@', 'recall@']
            thresholds:
                percentiles: [1.0, 2.0, 5.0, 10.0, 25.0, 50.0, 75.0, 95.0, 100.0]
                top_n: [5, 10, 25, 50, 75, 100, 150, 200, 300, 500, 1000, 2000]
    training_metric_groups:
      -
        metrics: [accuracy]
      -
        metrics: [precision@, recall@]
        thresholds:
          percentiles: [1.0, 2.0, 5.0, 10.0, 25.0, 50.0, 75.0, 95.0, 100.0]
          top_n: [5, 10, 25, 50, 75, 100, 150, 200, 300, 500, 1000, 2000]
#+END_SRC


#+BEGIN_SRC sh
./tutorial.sh triage --config_file inspections_label_failed_01.yaml validate
#+END_SRC

#+RESULTS:
#+BEGIN_SRC org
Using the config file /triage/experiment_config/inspections_label_failed_01.yaml
The output (matrices and models) of this experiment will be stored in triage/output
Using data stored in postgresql://food_user:some_password@food_db/food
The experiment will utilize any preexisting matrix or model: False
Creating experiment object
Experiment loaded
Validating experiment's configuration
Experiment validation ran to completion with no errors

----TIME SPLIT SUMMARY----

Number of time splits: 2
Split index 0:
            Training as_of_time_range: 2015-02-01 00:00:00 to 2016-01-01 00:00:00 (12 total)
            Testing as_of_time range: 2016-02-01 00:00:00 to 2016-02-01 00:00:00 (1 total)


Split index 1:
            Training as_of_time_range: 2015-02-01 00:00:00 to 2017-01-01 00:00:00 (24 total)
            Testing as_of_time range: 2017-02-01 00:00:00 to 2017-02-01 00:00:00 (1 total)


For more detailed information on your time splits, inspect the experiment `split_definitions` property

           The experiment configuration doesn't contain any obvious errors.
           Any error that occurs from now on, possibly will be related to hit the maximum
           number of columns allowed or collision in
           the column names, both due to PostgreSQL limitations.

The experiment looks in good shape. May the force be with you!
#+END_SRC

You can execute the experiment with

#+BEGIN_SRC sh
./tutorial.sh triage --config_file inspections_label_failed_01.yaml run
#+END_SRC

This will take a looooong time to run.

Well, now we have a lot of models. How can you pick the best one?
We will show you when we model /Early Warning/.
