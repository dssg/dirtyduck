#+TITLE: Dirty duck: A triage's guided tour
#+AUTHOR: Center of Data Science for Public Policy
#+EMAIL: adolfo@uchicago.edu
#+STARTUP: showeverything
#+STARTUP: nohideblocks
#+STARTUP: indent
#+PROPERTY: header-args:sql :engine postgresql
#+PROPERTY: header-args:sql+ :dbhost 0.0.0.0
#+PROPERTY: header-args:sql+ :dbport 5434
#+PROPERTY: header-args:sql+ :dbuser food_user
#+PROPERTY: header-args:sql+ :dbpassword some_password
#+PROPERTY: header-args:sql+ :database food
#+PROPERTY: header-args:sql+ :results table drawer
#+PROPERTY: header-args:shell     :results drawer
#+PROPERTY: header-args:ipython   :session :exports both :results raw drawer
#+PROPERTY: header-args:python   :session :exports both :results raw drawer

* Problem description

 /What are you inspecting?/ (people, places, other)
 /How far do you want to predict?/ (e.g. 1 mo, 6mo, 12 mo, etc)
 /How often do you want to update the list?/ (e.g. 1 mo, 6mo, 12 mo, etc)
 /What do you want to optimize for?/ (e.g. efficiency, long term
 compliance, novelty)


#+begin_quote
Will my restaurant be inspected in the
/next X period of time?/
#+end_quote

Where $X$ could be 1 month, 1 week, 1 year,
etc.

  Knowing the answer to this question, allows you (as the restaurant's
  owner) to be prepared and take the pertinent actions.


* Creating the labels

 #+begin_src sql
 select * from semantic.events limit 1
 #+end_src

 #+RESULTS:
 :RESULTS:
 | inspection | type    | license_num | facility_type | zip_code | city    |       date | risk   | result | violations                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     |
 |------------+---------+------------+--------------+---------+---------+------------+--------+--------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
 |     100209 | canvass |    1226806 | liquor       |   60622 | chicago | 2010-01-20 | medium | fail   | [{"code" : "13", "severity" : "critical", "description" : "NO EVIDENCE OF RODENT OR INSECT INFESTATION, NO BIRDS, TURTLES OR OTHER ANIMALS", "comment" : "All necessary control measures shall be used to effectively minimize or eliminate the presence of rodents, roaches, and other vermin/insect infestations"}, {"code" : "32", "severity" : "minor", "description" : "FOOD AND NON-FOOD CONTACT SURFACES PROPERLY DESIGNED, CONSTRUCTED AND MAINTAINED", "comment" : "All food and non-food contact equipment and utensils shall be smooth, easily cleanable, and durable, and shall be in good repair"}, {"code" : "33", "severity" : "minor", "description" : "FOOD AND NON-FOOD CONTACT EQUIPMENT UTENSILS CLEAN, FREE OF ABRASIVE DETERGENTS", "comment" : "All food and non-food contact surfaces of equipment and all food storage utensils shall be thoroughly cleaned and sanitized daily"}, {"code" : "34", "severity" : "minor", "description" : "FLOORS: CONSTRUCTED PER CODE, CLEANED, GOOD REPAIR, COVING INSTALLED, DUST-LESS CLEANING METHODS USED", "comment" : "The floors shall be constructed per code, be smooth and easily cleaned, and be kept clean and in good repair"}, {"code" : "38", "severity" : "minor", "description" : "VENTILATION: ROOMS AND EQUIPMENT VENTED AS REQUIRED: PLUMBING: INSTALLED AND MAINTAINED", "comment" : "Ventilation: All plumbing fixtures, such as toilets, sinks, washbasins, etc"}, {"code" : "41", "severity" : "minor", "description" : "PREMISES MAINTAINED FREE OF LITTER, UNNECESSARY ARTICLES, CLEANING  EQUIPMENT PROPERLY STORED", "comment" : "All parts of the food establishment and all parts of the property used in connection with the operation of the establishment shall be kept neat and clean and should not produce any offensive odors"}, {"code" : "42", "severity" : "minor", "description" : "APPROPRIATE METHOD OF HANDLING OF FOOD (ICE) HAIR RESTRAINTS AND CLEAN APPAREL WORN", "comment" : "All employees shall be required to use effective hair restraints to confine hair"}] |
 :END:



** Which facilities are likely to fail an inspection?

Facilities who failed an inspection (i.e. =result= = ='fail'=)

** Which facilities are likely  to fail an inspection with a major  violation?

Critical violations are coded between =1-14=, serious violations between
=15-29=, everything above =30= is assumed to be a minor violation.

Facilities who failed an inspection (i.e. =result= = ='fail'=) and the
=severity in ('critical', 'serious')=


#+begin_src sql

select inspection, result, array_agg(obj ->>'severity'),
(result = 'fail') as failed,
(result = 'fail' and
('serious' = ANY(array_agg(obj ->> 'severity')) or 'critical' = ANY(array_agg(obj ->> 'severity')))
) as failed_major_violation
from
(select inspection, result, jsonb_array_elements(violations::jsonb) as obj from semantic.events limit 20)
as t1
group by inspection, result

#+end_src

#+RESULTS:
:RESULTS:
| inspection | result             | array_agg                                                                             | failed | failed_major_violation |
|------------+--------------------+--------------------------------------------------------------------------------------+--------+----------------------|
|     285190 | pass w/ conditions | {minor,critical}                                                                     | f      | f                    |
|     285193 | fail               | {critical,critical,serious,critical,minor,minor,minor,critical,minor,minor,critical} | t      | t                    |
|     285191 | pass               | {minor,minor,minor,minor}                                                            | f      | f                    |
|     285192 | pass               | {NULL}                                                                               | f      | f                    |
|     285196 | fail               | {serious,critical}                                                                   | t      | t                    |
:END:


Let's use the previous query to generate our labels in the inspections schema

#+begin_src sql
create schema if not exists inspections
#+end_src

#+RESULTS:


#+begin_src sql

drop table if exists inspections.events;

create table inspections.events as (
with inspection_labels as (
select inspection, result,
   (result = 'fail') as failed,
   (result = 'fail' and
       ('serious' = ANY(array_agg(obj ->> 'severity')) or 'critical' = ANY(array_agg(obj ->> 'severity')))
   ) as failed_major_violation
from
   (select inspection, result, jsonb_array_elements(violations::jsonb) as obj from semantic.events)
as t1
group by inspection, result
)


select e.inspection, e.type, e.license_num, e.facility_type, e.zip_code, e.city, e.date, e.risk, e.result, failed, failed_major_violation
from
semantic.events as e
join
inspection_labels as l
on e.inspection = l.inspection
)
#+end_src

#+RESULTS:


* Modeling using Machine Learning

It is time of getting all the previous steps and put them
together. Don't worry, actually we are done coding. =triage= provides
you with a configuration file for specifying the experiment that we
want to run.

#+BEGIN_SRC yaml :tangle src/inspections_test.yaml
config_version: 'v3'

# EXPERIMENT METADATA
# model_comment (optional) will end up in the model_comment column of the
# models table for each model created in this experiment
model_comment: 'inspections_test'
#+END_SRC

#+BEGIN_SRC yaml :tangle src/inspections_test.yaml
temporal_config:
  feature_start_time='np.min(df.date)'
  feature_end_time='np.max(df.date)'
  label_start_time='np.min(df.date)'
  label_end_time='np.max(df.date)'
  model_update_frequency='3months'
  training_label_timespans='1day'
  training_as_of_date_frequencies='1day'
  max_training_histories='1year'
  test_durations='1day'
  test_label_timespans='3month'
  test_as_of_date_frequencies='1day'
#+END_SRC


#+BEGIN_SRC yaml :tangle src/inspections_test.yaml
events_table: inspections.events
#+END_SRC


#+BEGIN_SRC yaml :tangle src/inspections_test.yaml
feature_aggregations:
    -
        # prefix given to the resultant tables
        prefix: 'prefix'
        # from_obj is usually a source table but can be an expression, such as
        # a join (ie 'cool_stuff join other_stuff using (stuff_id)')
        from_obj: 'cool_stuff'
        # The date column to use for specifying which records to include
        # in temporal features. It is important that the column used specifies
        # the date at which the event is known about, which may be different
        # from the date the event happened.
        knowledge_date_column: 'open_date'

        # top-level imputation rules that will apply to all aggregates functions
        # can also specify categoricals_imputation or array_categoricals_imputation
        #
        # You must specified at least one of the top-level or feature-level imputation
        # to cover ever feature being defined.
        aggregates_imputation:
            # The `all` rule will apply to all aggregation functions, unless over-
            # ridden by a more specific one
            all:
                # every imputation rule must have a `type` parameter, while some
                # (like 'constant') have other required parameters (`value` here)
                type: 'constant'
                value: 0
            # specifying `max` here will take precedence over the `all` rule for
            # aggregations using a MAX() function
            max:
                type: 'mean'

        # aggregates and categoricals define the actual features created. So
        # at least one is required
        #
        # Aggregates of numerical columns. Each quantity is a number of some
        # sort, and the list of metrics are applied to each quantity
        aggregates:
            -
                quantity: 'homeless::INT'
                # Imputation rules specified at the level of specific features
                # will take precedence over the higer-level rules specified
                # above. Note that the 'count' and 'sum' metrics will be
                # imputed differently here.
                imputation:
                    count:
                        type: 'mean'
                    sum:
                        type: 'constant'
                        value: 137
                metrics:
                    - 'count'
                    - 'sum'
            -
                # since we're specifying `aggregates_imputation` above,
                # a feature-specific imputation rule can be omitted
                quantity: 'some_flag'
                metrics:
                    - 'max'
                    - 'sum'
        # Categorical features. The column given can be of any type, but the
        # choices must comparable to that type for equality within SQL
        # The result will be one feature for each choice/metric combination
        categoricals:
            -
                column: 'color'
                # note that we haven't specified a top level `categoricals_imputation`
                # set of rules, so we have to include feature-specific imputation
                # rules for both of our categoricals here.
                imputation:
                    sum:
                        type: 'null_category'
                    max:
                        type: 'mean'
                choices:
                    - 'red'
                    - 'blue'
                    - 'green'
                metrics:
                    - 'sum'
            -
                column: 'shape'
                # as with the top-level imputation rules, `all` can be used
                # for the feature-level rules to specify the same type of
                # imputation for all aggregation functions
                imputation:
                    all:
                        type: 'zero'
                choice_query: 'select distinct shape from cool_stuff'
                metrics:
                    - 'sum'
        # The time intervals over which to aggregate features
        intervals:
            - '1 year'
            - '2 years'
            - 'all'
        # A list of different columns to separately group by
        groups:
- 'entity_id'
#+END_SRC

#+BEGIN_SRC yaml :tangle src/inspections_test.yaml

# FEATURE GROUPING
# define how to group features and generate combinations
# feature_group_definition allows you to create groups/subset of your features
# by different criteria.
# for instance,
# - 'tables' allows you to send a list of collate feature tables (collate builds these by appending 'aggregation_imputed' to the prefix)
# - 'prefix' allows you to specify a list of feature name prefixes
feature_group_definition:
   tables: ['prefix_aggregation_imputed']
#+END_SRC


#+BEGIN_SRC yaml :tangle src/inspections_test.yaml
# STATE MANAGEMENT (optional)
# If you want to only include rows in your matrices in a specific state,
# provide:
# 1. a dense state table that defines when entities were in specific states
#   should have columns entity_id/state/start/end
# 2. a list of state filtering SQL clauses to iterate through. Assuming the
#   states are boolean columns (the experiment will convert the one you pass in
#   to this format), write a SQL expression for each state
#   configuration you want, ie '(permitted OR suspended) AND licensed'
state_config:
    table_name: 'states'
    state_filters:
        - 'state_one AND state_two'
        - '(state_one OR state_two) AND state_three'
#+END_SRC


#+BEGIN_SRC yaml :tangle src/inspections_test.yaml
# USER METADATA
# These are arbitrary keys/values that you can have Triage apply to the
# metadata for every matrix in the experiment. Any keys you include here can
# be used in the 'model_group_keys' below. For example, if you run experiments
# that share a temporal configuration but that use different label definitions
# (say, labeling building inspections with *any* violation as positive or
# labeling only building inspections with severe health and safety violations
# as positive), you can use the user metadata keys to indicate that the matrices
# from these experiments have different labeling criteria. The matrices from the
# two experiments will have different filenames (and not be overwritten or
# inappropriately reused), and if you add the label_definition key to the model
# group keys, models made on different label definition will have different
# groups. In this way, user metadata can be used to expand Triage beyond its
# explicitly supported functionality.
user_metadata:
  label_definition: 'severe_violations'
#+END_SRC

#+BEGIN_SRC yaml :tangle src/inspections_test.yaml
model_group_keys:
    - 'train_duration'
    - 'label_window'
    - 'example_frequency'
    - 'label_definition'
#+END_SRC

#+BEGIN_SRC yaml :tangle src/inspections_test.yaml
grid_config:
    'sklearn.ensemble.ExtraTreesClassifier':
        n_estimators: [100,100]
        criterion: [gini, entropy]
        max_depth: [1,5,10,20,50]
        max_features: [sqrt,log2]
        min_samples_split: [2,5,10]
#+END_SRC

#+BEGIN_SRC yaml :tangle src/inspections_test.yaml
scoring:
    sort_seed: 5
    metric_groups:
        -
            metrics: [precision@, recall@]
            thresholds:
                percentiles: [5.0, 10.0]
                top_n: [5, 10]
        -
            metrics: [f1]
        -
            metrics: [fbeta@]
            parameters:
                -
                    beta: 0.75
                -
                    beta: 1.25

#+END_SRC


#+BEGIN_SRC yaml :tangle src/inspections_test.yaml
# INDIVIDUAL IMPORTANCES
# How feature importances for individuals should be computed
# There are two variables here:
# methods: Refer to *how to compute* individual importances.
#   Each entry in this list should represent a different method.
#   Available methods are in the catwalk library's:
#   `catwalk.individual_importance.CALCULATE_STRATEGIES` list
#   Will default to 'uniform', or just the global importances.
#
# n_ranks: The number of top features per individual to compute importances for
#   Will default to 5
#
# This entire section can be left blank,
# in which case the defaults will be used.
individual_importance:
    methods: ['uniform']
    n_ranks: 5
#+END_SRC



** â–¶ TODO Creating a simple experiment

Using the same subset as before, we will try one of the simplest
machine learning algorithms: a Decision Tree Classifier

We began with this data set:

Our train matrices look like:

And the test matrices:

We can check the results of the experiment here:


Now let's do a real model

** Defining a baseline
It is always a good idea define a baseline, we will use

** The grid

** How can I pick the best one?


We are working in ...

But meanwhile, you can try the following
