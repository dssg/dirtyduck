#+TITLE: Dirty duck: A triage's guided tour
#+AUTHOR: Center of Data Science for Public Policy
#+EMAIL: adolfo@uchicago.edu
#+STARTUP: showeverything
#+STARTUP: nohideblocks
#+STARTUP: indent
#+PROPERTY: header-args:sql :engine postgresql
#+PROPERTY: header-args:sql+ :dbhost 0.0.0.0
#+PROPERTY: header-args:sql+ :dbport 5434
#+PROPERTY: header-args:sql+ :dbuser food_user
#+PROPERTY: header-args:sql+ :dbpassword some_password
#+PROPERTY: header-args:sql+ :database food
#+PROPERTY: header-args:sql+ :results table drawer
#+PROPERTY: header-args:shell     :results drawer
#+PROPERTY: header-args:ipython   :session food_inspections


* ▶ TODO Problem description
EIS the join starts from entity (entity centric) (if you don't have an outcome you are doing good)
#+begin_quote
Will my restaurant be inspected in the
/next X period of time?/
#+end_quote

Where $X$ could be 1 month, 1 week, 1 year,
etc.

  Knowing the answer to this question, allows you (as the restaurant's
  owner) to be prepared and take the pertinent actions.


* ▶ TODO The task as a multientity/multivariate time series problem


* ▶ TODO Creating the labels



* ▶ TODO Temporal crossvalidation

/There are three different ways of doing it/...

Avoid leakage ...

/It will easy to explain if we show this with only one facility/...

Enter =timechop=

Timechop requires the following parameters:


- =feature_start_time= - data aggregated into features begins at this point
# earliest date included in features
- =feature_end_time= - data aggregated into features is from before this
  point
# latest date included in features
- =label_start_time= - data aggregated into labels begins at this point
# earliest event date included in any label (event date >= label_start_time)
- =label_end_time= - data aggregated is from before this point
# event date < label_end_time to be included in any label
- =model_update_frequency= - amount of time between train/test splits
# how frequently to retrain models (days, months, years)
- =training_as_of_date_frequencies= - how much time between rows for a
  single entity in a training matrix
# list - time between rows for same entity in train matrix
- =max_training_histories= - the maximum amount of history for each
  entity to train on (early matrices may contain less than this time
  if it goes past label/feature start times)
# max length of time for labels included in a train matrix - default = max (label_start_time to now)
- =training_label_timespans= - how much time is covered by training
  labels (e.g., outcomes in the next 1 year? 3 days? 2 months?)
  (training prediction span)
# time period across which outcomes are determined in train matrices
- =test_as_of_date_frequencies= - how much time between rows for a
  single entity in a test matrix
# time between rows for same entity in test matrix  - inspections -  planning/scheduling frequency, eis = reviewing frequency (default = 1week)
- =test_durations= - how far into the future should a model be used to
  make predictions (in the typical case of wanting a single prediction
  set immediately after model training, this should be set to 0 days)
(test span)
# length of time included in a test matrix (default = training_prediction_span) inspections = how far out are you scheduling for? eis = model_update_frequency
- =test_label_timespans= - how much time is covered by test predictions
  (e.g., outcomes in the next 1 year? 3 days? 2 months?)
(test prediction span)
# time period across which outcomes are labeled in test matrices (default for eis = training_prediction_span, inspections = test_data_span)

In the particular case of *early intervention/warning systems*,

- =test_as_of_date_frequencies= is reviewing frequency
- =test_durations= is equal to =model_update_frequency=
- =test_label_timespans= is equal to =training_label_timespan=




* ▶ TODO Feature engineering

/We will show how to create features, we will use the same subset (one facility) and only one variable .../

Enter =collate=


* Modeling using Machine Learning


** ▶ TODO Creating a simple experiment

Using the same subset as before, we will try one of the simplest
machine learning algorithms: a Decision Tree Classifier

We began with this data set:

Our train matrices look like:

And the test matrices:

We can check the results of the experiment here:


Now let's do a real model

** Defining a baseline
It is always a good idea define a baseline, we will use

** The grid

** How can I pick the best one?


We are working in ...

But meanwhile, you can try the following

* What's next?

  - Add the shape file
    https://data.cityofchicago.org/api/geospatial/gdcf-axmw?method=export&format=Shapefile
  - Text analysis?
  - Run =pgdedup=
  - Routing based on the inspection list?
  - Add more data sources?
  - Postmodeling?
  - Bias analysis?


* Notes
[2018-01-01 Mon 00:50]


 /What are you inspecting?/ (people, places, other)
 /How far do you want to predict?/ (e.g. 1 mo, 6mo, 12 mo, etc)
 /How often do you want to update the list?/ (e.g. 1 mo, 6mo, 12 mo, etc)
 /What do you want to optimize for?/ (e.g. efficiency, long term
 compliance, novelty)


Inspection the join starts from outcomes (outcome centric) (if you
haven't been inspected, we can not said anything about you)
